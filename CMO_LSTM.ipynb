{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1q6ZiZBYdgXcuucMVImct1ICE0ZCmC4YC",
      "authorship_tag": "ABX9TyN7ALrFVw4bBKDSSFlCigv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHunor/CMO_NN/blob/main/CMO_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "11SGtxoF8-n9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "J0rxH7VHXCaW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_path = \"/content/dataset_all.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./DS_o\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_labels.zip\"\n",
        "#zip_path = keras.utils.get_file(origin=uri, fname=\"data_labels0.zip\")\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./labels\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_myo.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./myo\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_opt.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./op\")"
      ],
      "metadata": {
        "id": "grSS5FJ_9CHi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_ADRS = [];\n",
        "hp = './labels'\n",
        "p = '/'\n",
        "for child in Path(hp).iterdir():\n",
        "    if child.is_file():\n",
        "        L_ADRS.append(child.name)\n",
        "labels = [];\n",
        "for adrs in L_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#df = pd.read_csv(hp + p + adrs, header=None)\n",
        "    labels.append(df)"
      ],
      "metadata": {
        "id": "fqOaESPBSfSZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M_ADRS = [];\n",
        "hp = './myo'\n",
        "p = '/'\n",
        "for child in Path(hp).iterdir():\n",
        "    if child.is_file():\n",
        "        M_ADRS.append(child.name)\n",
        "myo = [];\n",
        "for adrs in M_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#= pd.read_csv(hp + p + adrs, header=None)\n",
        "    myo.append(df)"
      ],
      "metadata": {
        "id": "LrWD-KPzZVqy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "O_ADRS = [];\n",
        "hp = './op'\n",
        "p = '/'\n",
        "for child in Path(hp).iterdir():\n",
        "    if child.is_file():\n",
        "        O_ADRS.append(child.name)\n",
        "op = [];\n",
        "for adrs in O_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#df = pd.read_csv(hp + p + adrs, header=None)\n",
        "    op.append(df)"
      ],
      "metadata": {
        "id": "DwdKZutgZVTK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  df = pd.read_csv('./labels/' + ADRS[0])\n",
        "  labels = [];\n",
        "  labels.append(df)\n",
        "  df = pd.read_csv('./labels/' + ADRS[1])\n",
        "  labels.append(df)\n",
        "  print(labels)\n",
        "  print(labels[1])\n",
        "  print(df)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "d1XCwo_MTXny",
        "outputId": "ff26a07c-0931-42a8-dc72-1172a56c30a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  df = pd.read_csv('./labels/' + ADRS[0])\\n  labels = [];\\n  labels.append(df)\\n  df = pd.read_csv('./labels/' + ADRS[1])\\n  labels.append(df)\\n  print(labels)\\n  print(labels[1])\\n  print(df)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADRS = pd.read_csv(csv_path)\n",
        "#df = pd.read_csv(ADRS(i))\n"
      ],
      "metadata": {
        "id": "v07hnZzKgWu-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset and labels\n",
        "\n",
        "#model.reset_states() before feeding the new dataset and calling model.fit()\n",
        "# only myo 15 moves\n",
        "\n",
        "# opto too 15 moves\n",
        "\n",
        "# Have a CNN run thorugh 10 datappoint (one data point represents 10 ns)\n",
        "# 1. only CNN (17->18-20)\n",
        "# 2. only LSTM\n",
        "# 3. Both"
      ],
      "metadata": {
        "id": "sfrOZ9PC9lFX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.size(myo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLK4UUdFEzPO",
        "outputId": "5c914faa-1431-4e39-896f-fbd4df9af1d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return asarray(a).size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = myo[0]\n",
        "y_val = labels[0]\n",
        "\n",
        "sequence_length = 20\n",
        "step = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "for batch in dataset_val.take(1):\n",
        "    inputs, targets = batch"
      ],
      "metadata": {
        "id": "QVIaJR-iWASW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "i = 1;\n",
        "len = np.size(labels[i], 0)\n",
        "print(len)\n",
        "print(labels[0])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rXlrqkeJn6wC",
        "outputId": "c3b29915-fb1c-4e58-f1a5-6db0b8e37749"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni = 1;\\nlen = np.size(labels[i], 0)\\nprint(len)\\nprint(labels[0])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# will be repeated\n",
        "DS_T = [];\n",
        "for i, M in enumerate(myo[1:]):\n",
        "  if np.size(M, 0)<sequence_length:\n",
        "    continue\n",
        "  i = i+1\n",
        "  x_train = M\n",
        "  ishape = []\n",
        "  ishape.append(1)\n",
        "  ishape.append(np.size(M, 1))\n",
        "  y_train = labels[i]\n",
        "  oshape = []\n",
        "  oshape.append(1)\n",
        "  oshape.append(np.size(labels[i], 1))\n",
        "  dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "  DS_T.append(dataset_train)\n"
      ],
      "metadata": {
        "id": "o35Fo2XwnnUo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# will be repeated\n",
        "\n"
      ],
      "metadata": {
        "id": "jf7XuZyqVgDJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path_checkpoint1 =  \"model1_checkpoint.h5\"\n",
        "path_checkpoint2 =  \"model2_checkpoint.h5\"\n",
        "path_checkpoint3 =  \"model3_checkpoint.h5\"\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "modelckpt_callback1 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint1,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback2 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint2,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback3 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint3,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")"
      ],
      "metadata": {
        "id": "a41N44C2k33i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLe5uAR18RVz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#models\n",
        "#input_shape = (batch_size, sequence_length, ishape[1])\n",
        "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "#inputs = keras.layers.Input(shape=(ishape[0], ishape[1]))\n",
        "#inputs = keras.layers.Input(shape=(1,17))\n",
        "\n",
        "\n",
        "lstm_out = keras.layers.LSTM(32)(inputs)\n",
        "LSoutputs = keras.layers.Dense(oshape[1])(lstm_out)\n",
        "\n",
        "\"\"\"\n",
        "cnn_out1 = keras.layers.Conv1D(32, 1, activation='relu',input_shape=(inputs.shape[1], inputs.shape[2]))(inputs)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1])(cnn_out1)\n",
        "model1 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model1.summary()\n",
        "\"\"\"\n",
        "\n",
        "#x = tf.ones((batch_size, inputs.shape[1], inputs.shape[1]))\n",
        "#y = model1(x)\n",
        "#model1.summary()\n",
        "\n",
        "model2 = keras.Model(inputs=inputs, outputs=LSoutputs)\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model2.summary()\n",
        "\n",
        "\"\"\"\n",
        "lstm_out2 = keras.layers.LSTM(32)(cnn_out1)\n",
        "COMBoutputs = keras.layers.Dense(oshape[1])(lstm_out2)\n",
        "model3 = keras.Model(inputs=inputs, outputs=COMBoutputs)\n",
        "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model3.summary()\n",
        "\"\"\"\n",
        "\n",
        "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint1,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "pFtmZprc-Fc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022601c5-4f11-428b-8fae-639eb04e0be8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20, 8)]           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                5248      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                495       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,743\n",
            "Trainable params: 5,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# will be repeated\n",
        "for dataset_train in DS_T:\n",
        "  print(dataset_train)\n",
        "  history2 = model2.fit(\n",
        "      dataset_train,\n",
        "      epochs=epochs,\n",
        "      validation_data=dataset_val,\n",
        "      callbacks=[es_callback, modelckpt_callback2],\n",
        "  )\n",
        "  model2.reset_states() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx3-ezG1-GyX",
        "outputId": "23ea865c-c1be-4d66-9150-03df8482cca9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5237\n",
            "Epoch 1: val_loss improved from inf to 0.47504, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5237 - val_loss: 0.4750\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4968\n",
            "Epoch 2: val_loss improved from 0.47504 to 0.45394, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4968 - val_loss: 0.4539\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4717\n",
            "Epoch 3: val_loss improved from 0.45394 to 0.43424, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4717 - val_loss: 0.4342\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4480\n",
            "Epoch 4: val_loss improved from 0.43424 to 0.41574, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4480 - val_loss: 0.4157\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4257\n",
            "Epoch 5: val_loss improved from 0.41574 to 0.39823, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4257 - val_loss: 0.3982\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4546\n",
            "Epoch 1: val_loss improved from 0.39823 to 0.38146, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4546 - val_loss: 0.3815\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4327\n",
            "Epoch 2: val_loss improved from 0.38146 to 0.36528, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.4327 - val_loss: 0.3653\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4113\n",
            "Epoch 3: val_loss improved from 0.36528 to 0.34960, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4113 - val_loss: 0.3496\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3905\n",
            "Epoch 4: val_loss improved from 0.34960 to 0.33440, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3905 - val_loss: 0.3344\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3700\n",
            "Epoch 5: val_loss improved from 0.33440 to 0.31969, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3700 - val_loss: 0.3197\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3206\n",
            "Epoch 1: val_loss improved from 0.31969 to 0.30547, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3206 - val_loss: 0.3055\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3020\n",
            "Epoch 2: val_loss improved from 0.30547 to 0.29175, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3020 - val_loss: 0.2917\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2839\n",
            "Epoch 3: val_loss improved from 0.29175 to 0.27852, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2839 - val_loss: 0.2785\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2665\n",
            "Epoch 4: val_loss improved from 0.27852 to 0.26575, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2665 - val_loss: 0.2657\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2497\n",
            "Epoch 5: val_loss improved from 0.26575 to 0.25334, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2497 - val_loss: 0.2533\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2126\n",
            "Epoch 1: val_loss improved from 0.25334 to 0.24106, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2126 - val_loss: 0.2411\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2043\n",
            "Epoch 2: val_loss improved from 0.24106 to 0.22878, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2043 - val_loss: 0.2288\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1956\n",
            "Epoch 3: val_loss improved from 0.22878 to 0.21652, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1956 - val_loss: 0.2165\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1865\n",
            "Epoch 4: val_loss improved from 0.21652 to 0.20436, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1865 - val_loss: 0.2044\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1772\n",
            "Epoch 5: val_loss improved from 0.20436 to 0.19245, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1772 - val_loss: 0.1924\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1924\n",
            "Epoch 1: val_loss improved from 0.19245 to 0.18048, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1924 - val_loss: 0.1805\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1811\n",
            "Epoch 2: val_loss improved from 0.18048 to 0.16850, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1811 - val_loss: 0.1685\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1697\n",
            "Epoch 3: val_loss improved from 0.16850 to 0.15658, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1697 - val_loss: 0.1566\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1581\n",
            "Epoch 4: val_loss improved from 0.15658 to 0.14484, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1581 - val_loss: 0.1448\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1464\n",
            "Epoch 5: val_loss improved from 0.14484 to 0.13338, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.1464 - val_loss: 0.1334\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1561\n",
            "Epoch 1: val_loss improved from 0.13338 to 0.12217, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1561 - val_loss: 0.1222\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1440\n",
            "Epoch 2: val_loss improved from 0.12217 to 0.11132, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1440 - val_loss: 0.1113\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1319\n",
            "Epoch 3: val_loss improved from 0.11132 to 0.10098, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1319 - val_loss: 0.1010\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1200\n",
            "Epoch 4: val_loss improved from 0.10098 to 0.09130, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1200 - val_loss: 0.0913\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1084\n",
            "Epoch 5: val_loss improved from 0.09130 to 0.08244, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1084 - val_loss: 0.0824\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0749\n",
            "Epoch 1: val_loss improved from 0.08244 to 0.07434, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0749 - val_loss: 0.0743\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0640\n",
            "Epoch 2: val_loss improved from 0.07434 to 0.06714, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0640 - val_loss: 0.0671\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0539\n",
            "Epoch 3: val_loss improved from 0.06714 to 0.06095, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0539 - val_loss: 0.0610\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0448\n",
            "Epoch 4: val_loss improved from 0.06095 to 0.05583, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0448 - val_loss: 0.0558\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0366\n",
            "Epoch 5: val_loss improved from 0.05583 to 0.05176, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0366 - val_loss: 0.0518\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0256\n",
            "Epoch 1: val_loss improved from 0.05176 to 0.04851, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0256 - val_loss: 0.0485\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0210\n",
            "Epoch 2: val_loss improved from 0.04851 to 0.04589, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0210 - val_loss: 0.0459\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0173\n",
            "Epoch 3: val_loss improved from 0.04589 to 0.04368, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0173 - val_loss: 0.0437\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0142\n",
            "Epoch 4: val_loss improved from 0.04368 to 0.04170, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0142 - val_loss: 0.0417\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0117\n",
            "Epoch 5: val_loss improved from 0.04170 to 0.03982, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0117 - val_loss: 0.0398\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0128\n",
            "Epoch 1: val_loss improved from 0.03982 to 0.03812, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - val_loss: 0.0381\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0114\n",
            "Epoch 2: val_loss improved from 0.03812 to 0.03653, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0365\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 3: val_loss improved from 0.03653 to 0.03503, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - val_loss: 0.0350\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 4: val_loss improved from 0.03503 to 0.03361, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - val_loss: 0.0336\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0091\n",
            "Epoch 5: val_loss improved from 0.03361 to 0.03228, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - val_loss: 0.0323\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 1: val_loss improved from 0.03228 to 0.03070, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - val_loss: 0.0307\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 2: val_loss improved from 0.03070 to 0.02899, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0064 - val_loss: 0.0290\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 3: val_loss improved from 0.02899 to 0.02730, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - val_loss: 0.0273\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 4: val_loss improved from 0.02730 to 0.02575, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0055 - val_loss: 0.0258\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 5: val_loss improved from 0.02575 to 0.02442, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - val_loss: 0.0244\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 1: val_loss improved from 0.02442 to 0.02333, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - val_loss: 0.0233\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2: val_loss improved from 0.02333 to 0.02246, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - val_loss: 0.0225\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3: val_loss improved from 0.02246 to 0.02177, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0044 - val_loss: 0.0218\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 4: val_loss improved from 0.02177 to 0.02125, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0044 - val_loss: 0.0212\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 5: val_loss improved from 0.02125 to 0.02086, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0044 - val_loss: 0.0209\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 1: val_loss improved from 0.02086 to 0.02082, saving model to model2_checkpoint.h5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0118 - val_loss: 0.0208\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0112\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0112 - val_loss: 0.0212\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0101 - val_loss: 0.0219\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0085\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - val_loss: 0.0232\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0070 - val_loss: 0.0251\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0060 - val_loss: 0.0269\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0063\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0063 - val_loss: 0.0286\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0065 - val_loss: 0.0299\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0065 - val_loss: 0.0308\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0063\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - val_loss: 0.0312\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0071\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - val_loss: 0.0310\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0064 - val_loss: 0.0305\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - val_loss: 0.0297\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0045\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - val_loss: 0.0288\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - val_loss: 0.0278\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0218\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0218 - val_loss: 0.0275\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0227\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0227 - val_loss: 0.0276\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0228\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0228 - val_loss: 0.0281\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0222\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0222 - val_loss: 0.0289\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0210\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0210 - val_loss: 0.0302\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0460\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0460 - val_loss: 0.0311\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0462\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0462 - val_loss: 0.0315\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0458\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0458 - val_loss: 0.0316\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0448\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0448 - val_loss: 0.0314\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0434\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0434 - val_loss: 0.0311\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - val_loss: 0.0309\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - val_loss: 0.0307\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - val_loss: 0.0307\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - val_loss: 0.0307\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - val_loss: 0.0309\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3107\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3107 - val_loss: 0.0299\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2958\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2958 - val_loss: 0.0290\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2736\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2736 - val_loss: 0.0297\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2475\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2475 - val_loss: 0.0327\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2199\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2199 - val_loss: 0.0389\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0561\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0561 - val_loss: 0.0457\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0683\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0683 - val_loss: 0.0515\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0764\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0764 - val_loss: 0.0556\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0801\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0801 - val_loss: 0.0579\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0800\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0800 - val_loss: 0.0589\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0383\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0383 - val_loss: 0.0592\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0359\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0359 - val_loss: 0.0590\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0330\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0330 - val_loss: 0.0587\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0299 - val_loss: 0.0583\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0267\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0267 - val_loss: 0.0579\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0783\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0783 - val_loss: 0.0578\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0732\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0732 - val_loss: 0.0582\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0681\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0681 - val_loss: 0.0592\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0632\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0632 - val_loss: 0.0608\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0588\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0588 - val_loss: 0.0629\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0235 - val_loss: 0.0649\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0221\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0221 - val_loss: 0.0667\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0210\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0210 - val_loss: 0.0680\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0200\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0200 - val_loss: 0.0689\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0189\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0189 - val_loss: 0.0691\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0165\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0165 - val_loss: 0.0686\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0159\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0159 - val_loss: 0.0673\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0151\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0151 - val_loss: 0.0654\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0140\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0140 - val_loss: 0.0630\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0127\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0127 - val_loss: 0.0602\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0220\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0220 - val_loss: 0.0569\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0200\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0200 - val_loss: 0.0533\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0177\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0177 - val_loss: 0.0496\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0154\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0154 - val_loss: 0.0460\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0132\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0132 - val_loss: 0.0426\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - val_loss: 0.0397\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0048 - val_loss: 0.0372\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0048 - val_loss: 0.0351\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0049 - val_loss: 0.0332\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0050 - val_loss: 0.0316\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0031\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - val_loss: 0.0302\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - val_loss: 0.0289\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0277\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0267\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0028\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - val_loss: 0.0258\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0278\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0278 - val_loss: 0.0251\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0274\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0274 - val_loss: 0.0245\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0266\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0266 - val_loss: 0.0241\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0257\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0257 - val_loss: 0.0239\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0247\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0247 - val_loss: 0.0238\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0029\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - val_loss: 0.0240\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0028\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.0243\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - val_loss: 0.0248\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - val_loss: 0.0253\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0026\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - val_loss: 0.0260\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0265\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0270\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - val_loss: 0.0275\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0034\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - val_loss: 0.0278\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.0281\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0058\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0058 - val_loss: 0.0282\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0057\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - val_loss: 0.0281\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0055 - val_loss: 0.0279\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - val_loss: 0.0276\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0047 - val_loss: 0.0272\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0054\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0054 - val_loss: 0.0270\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - val_loss: 0.0268\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - val_loss: 0.0267\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - val_loss: 0.0267\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0046 - val_loss: 0.0268\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - val_loss: 0.0271\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0080\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0080 - val_loss: 0.0274\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0075 - val_loss: 0.0279\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0069 - val_loss: 0.0286\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0062 - val_loss: 0.0293\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0503\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0503 - val_loss: 0.0300\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0505\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0505 - val_loss: 0.0307\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0502\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0502 - val_loss: 0.0312\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0495\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0495 - val_loss: 0.0317\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0486\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0486 - val_loss: 0.0322\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - val_loss: 0.0327\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - val_loss: 0.0331\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - val_loss: 0.0335\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 0.0338\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - val_loss: 0.0341\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0083\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - val_loss: 0.0344\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - val_loss: 0.0347\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0075\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - val_loss: 0.0350\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - val_loss: 0.0354\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0064\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0064 - val_loss: 0.0358\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0129 - val_loss: 0.0360\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0130\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0130 - val_loss: 0.0360\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0128\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0128 - val_loss: 0.0358\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0123\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0123 - val_loss: 0.0356\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0116\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - val_loss: 0.0352\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0057\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - val_loss: 0.0348\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0055\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - val_loss: 0.0342\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - val_loss: 0.0336\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - val_loss: 0.0329\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - val_loss: 0.0322\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0546\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0546 - val_loss: 0.0315\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0543\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0543 - val_loss: 0.0307\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0537\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0537 - val_loss: 0.0300\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0530\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0530 - val_loss: 0.0293\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0522\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0522 - val_loss: 0.0288\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0614\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0614 - val_loss: 0.0283\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0606\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0606 - val_loss: 0.0280\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0597\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0597 - val_loss: 0.0277\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0587\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0587 - val_loss: 0.0276\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0576\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0576 - val_loss: 0.0277\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0124 - val_loss: 0.0278\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0129 - val_loss: 0.0279\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0132\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0132 - val_loss: 0.0280\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0133\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0133 - val_loss: 0.0281\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0131\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0131 - val_loss: 0.0281\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - val_loss: 0.0281\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - val_loss: 0.0280\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - val_loss: 0.0280\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0047 - val_loss: 0.0279\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - val_loss: 0.0279\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0096\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0096 - val_loss: 0.0279\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - val_loss: 0.0278\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - val_loss: 0.0277\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0084\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - val_loss: 0.0276\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0079\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - val_loss: 0.0274\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - val_loss: 0.0273\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - val_loss: 0.0273\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - val_loss: 0.0274\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0275\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0276\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0174\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0174 - val_loss: 0.0278\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0167\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0167 - val_loss: 0.0279\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0159\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0159 - val_loss: 0.0280\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0149\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0149 - val_loss: 0.0282\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0138\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0138 - val_loss: 0.0284\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - val_loss: 0.0287\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0056\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - val_loss: 0.0292\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - val_loss: 0.0296\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - val_loss: 0.0301\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - val_loss: 0.0307\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - val_loss: 0.0310\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - val_loss: 0.0312\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0042 - val_loss: 0.0311\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - val_loss: 0.0309\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0306\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0355\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0355 - val_loss: 0.0301\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0352\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0352 - val_loss: 0.0296\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0346\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0346 - val_loss: 0.0291\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0338\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0338 - val_loss: 0.0286\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0330\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0330 - val_loss: 0.0282\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0235\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0235 - val_loss: 0.0279\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0230\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0230 - val_loss: 0.0278\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0225\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0225 - val_loss: 0.0278\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0219\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0219 - val_loss: 0.0279\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0212\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0212 - val_loss: 0.0282\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - val_loss: 0.0287\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - val_loss: 0.0294\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - val_loss: 0.0303\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - val_loss: 0.0313\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0042\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - val_loss: 0.0324\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0101\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - val_loss: 0.0333\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0102\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - val_loss: 0.0340\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0102\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - val_loss: 0.0346\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0100\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - val_loss: 0.0350\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0097\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - val_loss: 0.0352\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0123\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0123 - val_loss: 0.0351\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0118\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0346\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0110\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0110 - val_loss: 0.0340\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0100\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - val_loss: 0.0332\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0089 - val_loss: 0.0323\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0309 - val_loss: 0.0315\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0310 - val_loss: 0.0308\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0310 - val_loss: 0.0301\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0310 - val_loss: 0.0296\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0310 - val_loss: 0.0290\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - val_loss: 0.0286\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0041 - val_loss: 0.0281\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0041 - val_loss: 0.0278\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0040\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0040 - val_loss: 0.0274\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0038 - val_loss: 0.0271\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0077\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0077 - val_loss: 0.0269\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0074\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0074 - val_loss: 0.0268\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0070 - val_loss: 0.0269\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0065\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0065 - val_loss: 0.0271\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0060\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0060 - val_loss: 0.0273\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0041 - val_loss: 0.0276\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0038\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0279\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - val_loss: 0.0282\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0285\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0029\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - val_loss: 0.0288\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - val_loss: 0.0291\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0029\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0029 - val_loss: 0.0293\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0296\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - val_loss: 0.0298\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - val_loss: 0.0300\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0212\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0212 - val_loss: 0.0301\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0211\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0211 - val_loss: 0.0301\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0206\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0206 - val_loss: 0.0301\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0198\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0198 - val_loss: 0.0300\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0188\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0188 - val_loss: 0.0300\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0050\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0050 - val_loss: 0.0300\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - val_loss: 0.0300\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - val_loss: 0.0300\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - val_loss: 0.0301\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0027\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.0303\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0048 - val_loss: 0.0305\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0053\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - val_loss: 0.0308\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0057\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - val_loss: 0.0310\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - val_loss: 0.0313\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - val_loss: 0.0315\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0274\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0274 - val_loss: 0.0312\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0270 - val_loss: 0.0304\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0262\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0262 - val_loss: 0.0294\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0250\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0250 - val_loss: 0.0280\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0237\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0237 - val_loss: 0.0265\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0127\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0127 - val_loss: 0.0253\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0126\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0244\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0124\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0124 - val_loss: 0.0236\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0120\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0120 - val_loss: 0.0231\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0114\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0114 - val_loss: 0.0228\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0819\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0819 - val_loss: 0.0227\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0800\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0800 - val_loss: 0.0228\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0769\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0769 - val_loss: 0.0233\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0731\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0731 - val_loss: 0.0242\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0688\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0688 - val_loss: 0.0256\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0068\n",
            "Epoch 1: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - val_loss: 0.0271\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 2: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - val_loss: 0.0286\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 3: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - val_loss: 0.0299\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 4: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - val_loss: 0.0310\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 5: val_loss did not improve from 0.02082\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - val_loss: 0.0319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "SqGdveimZ5e-",
        "outputId": "c9b8cd6f-8bca-41a7-b3f6-c4dc0e532a39"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-61f85ac40c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess time series into \"pics\"\n",
        "len = np.size(myo[0], 0)\n",
        "h = 8\n",
        "TrainDx = np.empty([0, h, 8, 1]).astype('float32')\n",
        "TrainDy = []\n",
        "TestDx = []\n",
        "TestDy = []\n",
        "for j in range(len-h):\n",
        "  #TD.append(myo[i:(h+1), 1:3])\n",
        "  TestDx.append(myo[0][j:j+h])\n",
        "  TestDy.append(labels[0][j+h-1:j+h])\n",
        "\n",
        "for k, L in  enumerate(myo[1:]):\n",
        "  print(\"k:\")\n",
        "  print(k)\n",
        "  if np.size(L, 0)<h:\n",
        "    continue\n",
        "  len2 = np.size(L, 0)\n",
        "  for j in range(len2-h):\n",
        "    print(\"j:\")\n",
        "    print(j)\n",
        "    #TD.append(myo[i:(h+1), 1:3])\n",
        "    arr =  np.asarray(L[j:j+h])\n",
        "    arr = np.reshape(arr, [1,  h, 8, 1])\n",
        "    print(arr.shape)\n",
        "    print(TrainDx.shape)\n",
        "    TrainDx = np.append(TrainDx, arr, axis=0)\n",
        "    TrainDy.append(np.asarray(labels[k+1][j+h-1:j+h]))\n",
        "print(np.size(TrainDx))\n",
        "print(\"TrainDx[0]:\")\n",
        "print(TrainDx[0])\n",
        "print(\"TrainDx size:\")\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "print(np.size(TrainDx[0], 0))\n",
        "#print(np.size(TrainDx, 2))\n",
        "print(TrainDy[0])\n",
        "print(np.size(TrainDy, 0))\n",
        "#print(np.size(TrainDy, 1))\n",
        "#print(labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLxsFlVCLeHp",
        "outputId": "438b0eda-ae9d-499b-ed05-c389157f4c13"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "(799, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(800, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(801, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(802, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(803, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(804, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(805, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(806, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(807, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(808, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(809, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(810, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(811, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(812, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(813, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(814, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(815, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(816, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(817, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(818, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(819, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(820, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(821, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(822, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(823, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(824, 8, 8, 1)\n",
            "k:\n",
            "27\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(825, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(826, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(827, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(828, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(829, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(830, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(831, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(832, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(833, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(834, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(835, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(836, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(837, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(838, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(839, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(840, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(841, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(842, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(843, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(844, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(845, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(846, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(847, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(848, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(849, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(850, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(851, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(852, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(853, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(854, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(855, 8, 8, 1)\n",
            "k:\n",
            "28\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(856, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(857, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(858, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(859, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(860, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(861, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(862, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(863, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(864, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(865, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(866, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(867, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(868, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(869, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(870, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(871, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(872, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(873, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(874, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(875, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(876, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(877, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(878, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(879, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(880, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(881, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(882, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(883, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(884, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(885, 8, 8, 1)\n",
            "k:\n",
            "29\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(886, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(887, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(888, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(889, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(890, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(891, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(892, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(893, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(894, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(895, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(896, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(897, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(898, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(899, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(900, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(901, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(902, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(903, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(904, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(905, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(906, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(907, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(908, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(909, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(910, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(911, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(912, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(913, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(914, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(915, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(916, 8, 8, 1)\n",
            "k:\n",
            "30\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(917, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(918, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(919, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(920, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(921, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(922, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(923, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(924, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(925, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(926, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(927, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(928, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(929, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(930, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(931, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(932, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(933, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(934, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(935, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(936, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(937, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(938, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(939, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(940, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(941, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(942, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(943, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(944, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(945, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(946, 8, 8, 1)\n",
            "k:\n",
            "31\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(947, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(948, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(949, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(950, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(951, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(952, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(953, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(954, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(955, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(956, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(957, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(958, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(959, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(960, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(961, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(962, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(963, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(964, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(965, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(966, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(967, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(968, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(969, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(970, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(971, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(972, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(973, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(974, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(975, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(976, 8, 8, 1)\n",
            "k:\n",
            "32\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(977, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(978, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(979, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(980, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(981, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(982, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(983, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(984, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(985, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(986, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(987, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(988, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(989, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(990, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(991, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(992, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(993, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(994, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(995, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(996, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(997, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(998, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(999, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1000, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1001, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1002, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1003, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1004, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1005, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1006, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1007, 8, 8, 1)\n",
            "k:\n",
            "33\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1008, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1009, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1010, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1011, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1012, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1013, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1014, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1015, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1016, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1017, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1018, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1019, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1020, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1021, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1022, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1023, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1024, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1025, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1026, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1027, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1028, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1029, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1030, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1031, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1032, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1033, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1034, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1035, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1036, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1037, 8, 8, 1)\n",
            "k:\n",
            "34\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1038, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1039, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1040, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1041, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1042, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1043, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1044, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1045, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1046, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1047, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1048, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1049, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1050, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1051, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1052, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1053, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1054, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1055, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1056, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1057, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1058, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1059, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1060, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1061, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1062, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1063, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1064, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1065, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1066, 8, 8, 1)\n",
            "k:\n",
            "35\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1067, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1068, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1069, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1070, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1071, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1072, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1073, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1074, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1075, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1076, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1077, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1078, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1079, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1080, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1081, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1082, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1083, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1084, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1085, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1086, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1087, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1088, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1089, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1090, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1091, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1092, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1093, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1094, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1095, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1096, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1097, 8, 8, 1)\n",
            "k:\n",
            "36\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1098, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1099, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1100, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1101, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1102, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1103, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1104, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1105, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1106, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1107, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1108, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1109, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1110, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1111, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1112, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1113, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1114, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1115, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1116, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1117, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1118, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1119, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1120, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1121, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1122, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1123, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1124, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1125, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1126, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1127, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1128, 8, 8, 1)\n",
            "k:\n",
            "37\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1129, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1130, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1131, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1132, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1133, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1134, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1135, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1136, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1137, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1138, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1139, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1140, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1141, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1142, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1143, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1144, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1145, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1146, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1147, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1148, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1149, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1150, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1151, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1152, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1153, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1154, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1155, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1156, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1157, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1158, 8, 8, 1)\n",
            "k:\n",
            "38\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1159, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1160, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1161, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1162, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1163, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1164, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1165, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1166, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1167, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1168, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1169, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1170, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1171, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1172, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1173, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1174, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1175, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1176, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1177, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1178, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1179, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1180, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1181, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1182, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1183, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1184, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1185, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1186, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1187, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1188, 8, 8, 1)\n",
            "k:\n",
            "39\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1189, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1190, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1191, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1192, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1193, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1194, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1195, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1196, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1197, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1198, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1199, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1200, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1201, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1202, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1203, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1204, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1205, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1206, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1207, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1208, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1209, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1210, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1211, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1212, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1213, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1214, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1215, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1216, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1217, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1218, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1219, 8, 8, 1)\n",
            "k:\n",
            "40\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1220, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1221, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1222, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1223, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1224, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1225, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1226, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1227, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1228, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1229, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1230, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1231, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1232, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1233, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1234, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1235, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1236, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1237, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1238, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1239, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1240, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1241, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1242, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1243, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1244, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1245, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1246, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1247, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1248, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1249, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1250, 8, 8, 1)\n",
            "k:\n",
            "41\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1251, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1252, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1253, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1254, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1255, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1256, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1257, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1258, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1259, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1260, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1261, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1262, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1263, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1264, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1265, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1266, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1267, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1268, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1269, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1270, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1271, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1272, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1273, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1274, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1275, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1276, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1277, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1278, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1279, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1280, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1281, 8, 8, 1)\n",
            "k:\n",
            "42\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1282, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1283, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1284, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1285, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1286, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1287, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1288, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1289, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1290, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1291, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1292, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1293, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1294, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1295, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1296, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1297, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1298, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1299, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1300, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1301, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1302, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1303, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1304, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1305, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1306, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1307, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1308, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1309, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1310, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1311, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1312, 8, 8, 1)\n",
            "k:\n",
            "43\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1313, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1314, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1315, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1316, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1317, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1318, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1319, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1320, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1321, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1322, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1323, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1324, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1325, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1326, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1327, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1328, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1329, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1330, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1331, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1332, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1333, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1334, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1335, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1336, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1337, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1338, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1339, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1340, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1341, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1342, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1343, 8, 8, 1)\n",
            "k:\n",
            "44\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1344, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1345, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1346, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1347, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1348, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1349, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1350, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1351, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1352, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1353, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1354, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1355, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1356, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1357, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1358, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1359, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1360, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1361, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1362, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1363, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1364, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1365, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1366, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1367, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1368, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1369, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1370, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1371, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1372, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1373, 8, 8, 1)\n",
            "k:\n",
            "45\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1374, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1375, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1376, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1377, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1378, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1379, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1380, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1381, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1382, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1383, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1384, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1385, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1386, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1387, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1388, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1389, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1390, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1391, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1392, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1393, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1394, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1395, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1396, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1397, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1398, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1399, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1400, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1401, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1402, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1403, 8, 8, 1)\n",
            "k:\n",
            "46\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1404, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1405, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1406, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1407, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1408, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1409, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1410, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1411, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1412, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1413, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1414, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1415, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1416, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1417, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1418, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1419, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1420, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1421, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1422, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1423, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1424, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1425, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1426, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1427, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1428, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1429, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1430, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1431, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1432, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1433, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1434, 8, 8, 1)\n",
            "k:\n",
            "47\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1435, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1436, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1437, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1438, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1439, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1440, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1441, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1442, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1443, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1444, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1445, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1446, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1447, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1448, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1449, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1450, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1451, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1452, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1453, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1454, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1455, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1456, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1457, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1458, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1459, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1460, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1461, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1462, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1463, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1464, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1465, 8, 8, 1)\n",
            "j:\n",
            "31\n",
            "(1, 8, 8, 1)\n",
            "(1466, 8, 8, 1)\n",
            "j:\n",
            "32\n",
            "(1, 8, 8, 1)\n",
            "(1467, 8, 8, 1)\n",
            "j:\n",
            "33\n",
            "(1, 8, 8, 1)\n",
            "(1468, 8, 8, 1)\n",
            "j:\n",
            "34\n",
            "(1, 8, 8, 1)\n",
            "(1469, 8, 8, 1)\n",
            "j:\n",
            "35\n",
            "(1, 8, 8, 1)\n",
            "(1470, 8, 8, 1)\n",
            "j:\n",
            "36\n",
            "(1, 8, 8, 1)\n",
            "(1471, 8, 8, 1)\n",
            "j:\n",
            "37\n",
            "(1, 8, 8, 1)\n",
            "(1472, 8, 8, 1)\n",
            "j:\n",
            "38\n",
            "(1, 8, 8, 1)\n",
            "(1473, 8, 8, 1)\n",
            "j:\n",
            "39\n",
            "(1, 8, 8, 1)\n",
            "(1474, 8, 8, 1)\n",
            "j:\n",
            "40\n",
            "(1, 8, 8, 1)\n",
            "(1475, 8, 8, 1)\n",
            "j:\n",
            "41\n",
            "(1, 8, 8, 1)\n",
            "(1476, 8, 8, 1)\n",
            "j:\n",
            "42\n",
            "(1, 8, 8, 1)\n",
            "(1477, 8, 8, 1)\n",
            "j:\n",
            "43\n",
            "(1, 8, 8, 1)\n",
            "(1478, 8, 8, 1)\n",
            "j:\n",
            "44\n",
            "(1, 8, 8, 1)\n",
            "(1479, 8, 8, 1)\n",
            "j:\n",
            "45\n",
            "(1, 8, 8, 1)\n",
            "(1480, 8, 8, 1)\n",
            "j:\n",
            "46\n",
            "(1, 8, 8, 1)\n",
            "(1481, 8, 8, 1)\n",
            "j:\n",
            "47\n",
            "(1, 8, 8, 1)\n",
            "(1482, 8, 8, 1)\n",
            "j:\n",
            "48\n",
            "(1, 8, 8, 1)\n",
            "(1483, 8, 8, 1)\n",
            "j:\n",
            "49\n",
            "(1, 8, 8, 1)\n",
            "(1484, 8, 8, 1)\n",
            "j:\n",
            "50\n",
            "(1, 8, 8, 1)\n",
            "(1485, 8, 8, 1)\n",
            "j:\n",
            "51\n",
            "(1, 8, 8, 1)\n",
            "(1486, 8, 8, 1)\n",
            "j:\n",
            "52\n",
            "(1, 8, 8, 1)\n",
            "(1487, 8, 8, 1)\n",
            "j:\n",
            "53\n",
            "(1, 8, 8, 1)\n",
            "(1488, 8, 8, 1)\n",
            "j:\n",
            "54\n",
            "(1, 8, 8, 1)\n",
            "(1489, 8, 8, 1)\n",
            "j:\n",
            "55\n",
            "(1, 8, 8, 1)\n",
            "(1490, 8, 8, 1)\n",
            "j:\n",
            "56\n",
            "(1, 8, 8, 1)\n",
            "(1491, 8, 8, 1)\n",
            "j:\n",
            "57\n",
            "(1, 8, 8, 1)\n",
            "(1492, 8, 8, 1)\n",
            "j:\n",
            "58\n",
            "(1, 8, 8, 1)\n",
            "(1493, 8, 8, 1)\n",
            "j:\n",
            "59\n",
            "(1, 8, 8, 1)\n",
            "(1494, 8, 8, 1)\n",
            "j:\n",
            "60\n",
            "(1, 8, 8, 1)\n",
            "(1495, 8, 8, 1)\n",
            "j:\n",
            "61\n",
            "(1, 8, 8, 1)\n",
            "(1496, 8, 8, 1)\n",
            "j:\n",
            "62\n",
            "(1, 8, 8, 1)\n",
            "(1497, 8, 8, 1)\n",
            "j:\n",
            "63\n",
            "(1, 8, 8, 1)\n",
            "(1498, 8, 8, 1)\n",
            "j:\n",
            "64\n",
            "(1, 8, 8, 1)\n",
            "(1499, 8, 8, 1)\n",
            "j:\n",
            "65\n",
            "(1, 8, 8, 1)\n",
            "(1500, 8, 8, 1)\n",
            "j:\n",
            "66\n",
            "(1, 8, 8, 1)\n",
            "(1501, 8, 8, 1)\n",
            "j:\n",
            "67\n",
            "(1, 8, 8, 1)\n",
            "(1502, 8, 8, 1)\n",
            "j:\n",
            "68\n",
            "(1, 8, 8, 1)\n",
            "(1503, 8, 8, 1)\n",
            "j:\n",
            "69\n",
            "(1, 8, 8, 1)\n",
            "(1504, 8, 8, 1)\n",
            "j:\n",
            "70\n",
            "(1, 8, 8, 1)\n",
            "(1505, 8, 8, 1)\n",
            "j:\n",
            "71\n",
            "(1, 8, 8, 1)\n",
            "(1506, 8, 8, 1)\n",
            "j:\n",
            "72\n",
            "(1, 8, 8, 1)\n",
            "(1507, 8, 8, 1)\n",
            "j:\n",
            "73\n",
            "(1, 8, 8, 1)\n",
            "(1508, 8, 8, 1)\n",
            "j:\n",
            "74\n",
            "(1, 8, 8, 1)\n",
            "(1509, 8, 8, 1)\n",
            "j:\n",
            "75\n",
            "(1, 8, 8, 1)\n",
            "(1510, 8, 8, 1)\n",
            "j:\n",
            "76\n",
            "(1, 8, 8, 1)\n",
            "(1511, 8, 8, 1)\n",
            "j:\n",
            "77\n",
            "(1, 8, 8, 1)\n",
            "(1512, 8, 8, 1)\n",
            "j:\n",
            "78\n",
            "(1, 8, 8, 1)\n",
            "(1513, 8, 8, 1)\n",
            "j:\n",
            "79\n",
            "(1, 8, 8, 1)\n",
            "(1514, 8, 8, 1)\n",
            "j:\n",
            "80\n",
            "(1, 8, 8, 1)\n",
            "(1515, 8, 8, 1)\n",
            "j:\n",
            "81\n",
            "(1, 8, 8, 1)\n",
            "(1516, 8, 8, 1)\n",
            "j:\n",
            "82\n",
            "(1, 8, 8, 1)\n",
            "(1517, 8, 8, 1)\n",
            "j:\n",
            "83\n",
            "(1, 8, 8, 1)\n",
            "(1518, 8, 8, 1)\n",
            "j:\n",
            "84\n",
            "(1, 8, 8, 1)\n",
            "(1519, 8, 8, 1)\n",
            "j:\n",
            "85\n",
            "(1, 8, 8, 1)\n",
            "(1520, 8, 8, 1)\n",
            "j:\n",
            "86\n",
            "(1, 8, 8, 1)\n",
            "(1521, 8, 8, 1)\n",
            "j:\n",
            "87\n",
            "(1, 8, 8, 1)\n",
            "(1522, 8, 8, 1)\n",
            "j:\n",
            "88\n",
            "(1, 8, 8, 1)\n",
            "(1523, 8, 8, 1)\n",
            "j:\n",
            "89\n",
            "(1, 8, 8, 1)\n",
            "(1524, 8, 8, 1)\n",
            "j:\n",
            "90\n",
            "(1, 8, 8, 1)\n",
            "(1525, 8, 8, 1)\n",
            "j:\n",
            "91\n",
            "(1, 8, 8, 1)\n",
            "(1526, 8, 8, 1)\n",
            "j:\n",
            "92\n",
            "(1, 8, 8, 1)\n",
            "(1527, 8, 8, 1)\n",
            "j:\n",
            "93\n",
            "(1, 8, 8, 1)\n",
            "(1528, 8, 8, 1)\n",
            "j:\n",
            "94\n",
            "(1, 8, 8, 1)\n",
            "(1529, 8, 8, 1)\n",
            "j:\n",
            "95\n",
            "(1, 8, 8, 1)\n",
            "(1530, 8, 8, 1)\n",
            "j:\n",
            "96\n",
            "(1, 8, 8, 1)\n",
            "(1531, 8, 8, 1)\n",
            "j:\n",
            "97\n",
            "(1, 8, 8, 1)\n",
            "(1532, 8, 8, 1)\n",
            "j:\n",
            "98\n",
            "(1, 8, 8, 1)\n",
            "(1533, 8, 8, 1)\n",
            "j:\n",
            "99\n",
            "(1, 8, 8, 1)\n",
            "(1534, 8, 8, 1)\n",
            "j:\n",
            "100\n",
            "(1, 8, 8, 1)\n",
            "(1535, 8, 8, 1)\n",
            "j:\n",
            "101\n",
            "(1, 8, 8, 1)\n",
            "(1536, 8, 8, 1)\n",
            "j:\n",
            "102\n",
            "(1, 8, 8, 1)\n",
            "(1537, 8, 8, 1)\n",
            "j:\n",
            "103\n",
            "(1, 8, 8, 1)\n",
            "(1538, 8, 8, 1)\n",
            "j:\n",
            "104\n",
            "(1, 8, 8, 1)\n",
            "(1539, 8, 8, 1)\n",
            "j:\n",
            "105\n",
            "(1, 8, 8, 1)\n",
            "(1540, 8, 8, 1)\n",
            "j:\n",
            "106\n",
            "(1, 8, 8, 1)\n",
            "(1541, 8, 8, 1)\n",
            "j:\n",
            "107\n",
            "(1, 8, 8, 1)\n",
            "(1542, 8, 8, 1)\n",
            "j:\n",
            "108\n",
            "(1, 8, 8, 1)\n",
            "(1543, 8, 8, 1)\n",
            "j:\n",
            "109\n",
            "(1, 8, 8, 1)\n",
            "(1544, 8, 8, 1)\n",
            "k:\n",
            "48\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1545, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1546, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1547, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1548, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1549, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1550, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1551, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1552, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1553, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1554, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1555, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1556, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1557, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1558, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1559, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1560, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1561, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1562, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1563, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1564, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1565, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1566, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1567, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1568, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1569, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1570, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1571, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1572, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1573, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1574, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1575, 8, 8, 1)\n",
            "k:\n",
            "49\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1576, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1577, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1578, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1579, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1580, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1581, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1582, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1583, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1584, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1585, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1586, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1587, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1588, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1589, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1590, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1591, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1592, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1593, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1594, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1595, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1596, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1597, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1598, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1599, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1600, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1601, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1602, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1603, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1604, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1605, 8, 8, 1)\n",
            "k:\n",
            "50\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1606, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1607, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1608, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1609, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1610, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1611, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1612, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1613, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1614, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1615, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1616, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1617, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1618, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1619, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1620, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1621, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1622, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1623, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1624, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1625, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1626, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1627, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1628, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1629, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1630, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1631, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1632, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1633, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1634, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1635, 8, 8, 1)\n",
            "k:\n",
            "51\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1636, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1637, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1638, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1639, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1640, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1641, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1642, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1643, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1644, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1645, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1646, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1647, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1648, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1649, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1650, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1651, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1652, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1653, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1654, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1655, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1656, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1657, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1658, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1659, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1660, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1661, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1662, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1663, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1664, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1665, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1666, 8, 8, 1)\n",
            "k:\n",
            "52\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1667, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1668, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1669, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1670, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1671, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1672, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1673, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1674, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1675, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1676, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1677, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1678, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1679, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1680, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1681, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1682, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1683, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1684, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1685, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1686, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1687, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1688, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1689, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1690, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1691, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1692, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1693, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1694, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1695, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1696, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1697, 8, 8, 1)\n",
            "k:\n",
            "53\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1698, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1699, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1700, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1701, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1702, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1703, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1704, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1705, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1706, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1707, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1708, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1709, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1710, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1711, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1712, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1713, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1714, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1715, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1716, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1717, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1718, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1719, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1720, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1721, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1722, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1723, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1724, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1725, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1726, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1727, 8, 8, 1)\n",
            "k:\n",
            "54\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1728, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1729, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1730, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1731, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1732, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1733, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1734, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1735, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1736, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1737, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1738, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1739, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1740, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1741, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1742, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1743, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1744, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1745, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1746, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1747, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1748, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1749, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1750, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1751, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1752, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1753, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1754, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1755, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1756, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1757, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1758, 8, 8, 1)\n",
            "k:\n",
            "55\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1759, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1760, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1761, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1762, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1763, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1764, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1765, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1766, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1767, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1768, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1769, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1770, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1771, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1772, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1773, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1774, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1775, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1776, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1777, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1778, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1779, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1780, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1781, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1782, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1783, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1784, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1785, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1786, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1787, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1788, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1789, 8, 8, 1)\n",
            "k:\n",
            "56\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1790, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1791, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1792, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1793, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1794, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1795, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1796, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1797, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1798, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1799, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1800, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1801, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1802, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1803, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1804, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1805, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1806, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1807, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1808, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1809, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1810, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1811, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1812, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1813, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1814, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1815, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1816, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1817, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1818, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1819, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1820, 8, 8, 1)\n",
            "k:\n",
            "57\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1821, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1822, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1823, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1824, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1825, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1826, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1827, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1828, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1829, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1830, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1831, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1832, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1833, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1834, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1835, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1836, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1837, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1838, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1839, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1840, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1841, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1842, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1843, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1844, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1845, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1846, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1847, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1848, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1849, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1850, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1851, 8, 8, 1)\n",
            "k:\n",
            "58\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1852, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1853, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1854, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1855, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1856, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1857, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1858, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1859, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1860, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1861, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1862, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1863, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1864, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1865, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1866, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1867, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1868, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1869, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1870, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1871, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1872, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1873, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1874, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1875, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1876, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1877, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1878, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1879, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1880, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1881, 8, 8, 1)\n",
            "k:\n",
            "59\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1882, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1883, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1884, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1885, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1886, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1887, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1888, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1889, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1890, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1891, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1892, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1893, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1894, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1895, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1896, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1897, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1898, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1899, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1900, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1901, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1902, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1903, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1904, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1905, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1906, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1907, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1908, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1909, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1910, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1911, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1912, 8, 8, 1)\n",
            "j:\n",
            "31\n",
            "(1, 8, 8, 1)\n",
            "(1913, 8, 8, 1)\n",
            "k:\n",
            "60\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1914, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1915, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1916, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1917, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1918, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1919, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1920, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1921, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1922, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1923, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1924, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1925, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1926, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1927, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1928, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1929, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1930, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1931, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1932, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1933, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1934, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1935, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1936, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1937, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1938, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1939, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1940, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1941, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1942, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1943, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1944, 8, 8, 1)\n",
            "k:\n",
            "61\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1945, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1946, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1947, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1948, 8, 8, 1)\n",
            "k:\n",
            "62\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1949, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1950, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1951, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1952, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1953, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1954, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1955, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1956, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1957, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1958, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1959, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1960, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1961, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1962, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1963, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1964, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1965, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1966, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1967, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1968, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(1969, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(1970, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(1971, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(1972, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(1973, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(1974, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(1975, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(1976, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(1977, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(1978, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(1979, 8, 8, 1)\n",
            "k:\n",
            "63\n",
            "j:\n",
            "0\n",
            "(1, 8, 8, 1)\n",
            "(1980, 8, 8, 1)\n",
            "j:\n",
            "1\n",
            "(1, 8, 8, 1)\n",
            "(1981, 8, 8, 1)\n",
            "j:\n",
            "2\n",
            "(1, 8, 8, 1)\n",
            "(1982, 8, 8, 1)\n",
            "j:\n",
            "3\n",
            "(1, 8, 8, 1)\n",
            "(1983, 8, 8, 1)\n",
            "j:\n",
            "4\n",
            "(1, 8, 8, 1)\n",
            "(1984, 8, 8, 1)\n",
            "j:\n",
            "5\n",
            "(1, 8, 8, 1)\n",
            "(1985, 8, 8, 1)\n",
            "j:\n",
            "6\n",
            "(1, 8, 8, 1)\n",
            "(1986, 8, 8, 1)\n",
            "j:\n",
            "7\n",
            "(1, 8, 8, 1)\n",
            "(1987, 8, 8, 1)\n",
            "j:\n",
            "8\n",
            "(1, 8, 8, 1)\n",
            "(1988, 8, 8, 1)\n",
            "j:\n",
            "9\n",
            "(1, 8, 8, 1)\n",
            "(1989, 8, 8, 1)\n",
            "j:\n",
            "10\n",
            "(1, 8, 8, 1)\n",
            "(1990, 8, 8, 1)\n",
            "j:\n",
            "11\n",
            "(1, 8, 8, 1)\n",
            "(1991, 8, 8, 1)\n",
            "j:\n",
            "12\n",
            "(1, 8, 8, 1)\n",
            "(1992, 8, 8, 1)\n",
            "j:\n",
            "13\n",
            "(1, 8, 8, 1)\n",
            "(1993, 8, 8, 1)\n",
            "j:\n",
            "14\n",
            "(1, 8, 8, 1)\n",
            "(1994, 8, 8, 1)\n",
            "j:\n",
            "15\n",
            "(1, 8, 8, 1)\n",
            "(1995, 8, 8, 1)\n",
            "j:\n",
            "16\n",
            "(1, 8, 8, 1)\n",
            "(1996, 8, 8, 1)\n",
            "j:\n",
            "17\n",
            "(1, 8, 8, 1)\n",
            "(1997, 8, 8, 1)\n",
            "j:\n",
            "18\n",
            "(1, 8, 8, 1)\n",
            "(1998, 8, 8, 1)\n",
            "j:\n",
            "19\n",
            "(1, 8, 8, 1)\n",
            "(1999, 8, 8, 1)\n",
            "j:\n",
            "20\n",
            "(1, 8, 8, 1)\n",
            "(2000, 8, 8, 1)\n",
            "j:\n",
            "21\n",
            "(1, 8, 8, 1)\n",
            "(2001, 8, 8, 1)\n",
            "j:\n",
            "22\n",
            "(1, 8, 8, 1)\n",
            "(2002, 8, 8, 1)\n",
            "j:\n",
            "23\n",
            "(1, 8, 8, 1)\n",
            "(2003, 8, 8, 1)\n",
            "j:\n",
            "24\n",
            "(1, 8, 8, 1)\n",
            "(2004, 8, 8, 1)\n",
            "j:\n",
            "25\n",
            "(1, 8, 8, 1)\n",
            "(2005, 8, 8, 1)\n",
            "j:\n",
            "26\n",
            "(1, 8, 8, 1)\n",
            "(2006, 8, 8, 1)\n",
            "j:\n",
            "27\n",
            "(1, 8, 8, 1)\n",
            "(2007, 8, 8, 1)\n",
            "j:\n",
            "28\n",
            "(1, 8, 8, 1)\n",
            "(2008, 8, 8, 1)\n",
            "j:\n",
            "29\n",
            "(1, 8, 8, 1)\n",
            "(2009, 8, 8, 1)\n",
            "j:\n",
            "30\n",
            "(1, 8, 8, 1)\n",
            "(2010, 8, 8, 1)\n",
            "128704\n",
            "TrainDx[0]:\n",
            "[[[0.48866924]\n",
            "  [0.46018756]\n",
            "  [0.49453728]\n",
            "  [0.43639843]\n",
            "  [0.50126369]\n",
            "  [0.51810921]\n",
            "  [0.44587989]\n",
            "  [0.50005197]]\n",
            "\n",
            " [[0.47661524]\n",
            "  [0.41397451]\n",
            "  [0.48114824]\n",
            "  [0.43333211]\n",
            "  [0.47177759]\n",
            "  [0.50823303]\n",
            "  [0.43715084]\n",
            "  [0.50265045]]\n",
            "\n",
            " [[0.47836078]\n",
            "  [0.42086747]\n",
            "  [0.47095766]\n",
            "  [0.50382638]\n",
            "  [0.52506532]\n",
            "  [0.50608777]\n",
            "  [0.43967895]\n",
            "  [0.49926387]]\n",
            "\n",
            " [[0.4843298 ]\n",
            "  [0.46819783]\n",
            "  [0.47782776]\n",
            "  [0.53820019]\n",
            "  [0.5390059 ]\n",
            "  [0.50230732]\n",
            "  [0.44622905]\n",
            "  [0.49236046]]\n",
            "\n",
            " [[0.4903568 ]\n",
            "  [0.48668305]\n",
            "  [0.47943445]\n",
            "  [0.53176093]\n",
            "  [0.53016007]\n",
            "  [0.50971446]\n",
            "  [0.44622905]\n",
            "  [0.49859682]]\n",
            "\n",
            " [[0.49349084]\n",
            "  [0.44878834]\n",
            "  [0.44312339]\n",
            "  [0.46276876]\n",
            "  [0.52662174]\n",
            "  [0.51475131]\n",
            "  [0.44553073]\n",
            "  [0.49859682]]\n",
            "\n",
            " [[0.4843298 ]\n",
            "  [0.45733776]\n",
            "  [0.51092545]\n",
            "  [0.49202144]\n",
            "  [0.50450716]\n",
            "  [0.50556646]\n",
            "  [0.4411662 ]\n",
            "  [0.5       ]]\n",
            "\n",
            " [[0.49541948]\n",
            "  [0.48391026]\n",
            "  [0.56940874]\n",
            "  [0.5319449 ]\n",
            "  [0.49389217]\n",
            "  [0.4886782 ]\n",
            "  [0.43680168]\n",
            "  [0.50982226]]]\n",
            "TrainDx size:\n",
            "128704\n",
            "2011\n",
            "8\n",
            "[[0.53472244 0.36318209 0.71250005 0.46284047 0.77255352 0.86039275\n",
            "  0.41875023 0.7717398  0.87690894 0.47058782 0.74193548 0.93173478\n",
            "  0.61882063 0.64293754 0.96416624]]\n",
            "2011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "TrainDx = np.asarray(TrainDx)\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "arr = np.array(TrainDx)\n",
        "print(np.size(arr))\n",
        "print(np.size(arr, 0))\n",
        "TrainDx = TrainDx.reshape(np.size(TrainDx, 0), h, 8, 1)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3GWb8t2IfU3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TrainDx.dtypes)\n",
        "print(TrainDy.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "JAdlh7ZuMQ3w",
        "outputId": "c52f9a3d-1328-4238-d8a1-3dad5753f9b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-52a9a530ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainDx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainDy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dtypes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TrainDy = np.asarray(TrainDy).astype('float32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "BpZh9djvhQU3",
        "outputId": "53a63def-b768-4063-d6f1-5b2a14f8e068"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-d7ba68a995a8>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  TrainDy = np.asarray(TrainDy).astype('float32')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d7ba68a995a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrainDy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainDy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TestDx = np.asarray(TestDx).astype('float32')\n",
        "TestDx = TestDx.reshape(np.size(TestDx, 0), np.size(TestDx, 1), np.size(TestDx, 2), 1)\n",
        "\n",
        "TestDy = np.asarray(TestDy).astype('float32')"
      ],
      "metadata": {
        "id": "eTRpx8e2hAsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = TrainDx.shape\n",
        "print(input_shape)\n",
        "Kern1 = [2,1,1]\n",
        "Kern2 = [3,3,2]\n",
        "Kern = Kern2"
      ],
      "metadata": {
        "id": "JR1HoTu-iScj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(input_shape)\n",
        "inputs = keras.layers.Input(shape=input_shape[1:])\n",
        "cnn_out1 = keras.layers.Conv2D(16, kernel_size = (3, Kern[0]), activation = 'relu', input_shape = input_shape[1:])(inputs)\n",
        "cnn_out2 = keras.layers.Conv2D(32, kernel_size = (3, Kern[1]), activation = 'relu')(cnn_out1)\n",
        "cnn_out3 = keras.layers.MaxPooling2D(pool_size = (2, Kern[2]))(cnn_out2)\n",
        "cnn_out4 = keras.layers.Flatten()(cnn_out3)\n",
        "cnn_out5 = keras.layers.Dense(64, activation = 'relu')(cnn_out4)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1], activation = 'softmax')(cnn_out5)\n",
        "model1 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model1.summary()\n",
        "\n",
        "history1 = model1.fit(\n",
        "  TrainDx, TrainDy,\n",
        "  batch_size = batch_size,\n",
        "  epochs = epochs,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestDx, TestDy),\n",
        "  callbacks=[es_callback, modelckpt_callback1]\n",
        ")"
      ],
      "metadata": {
        "id": "hzoQ84d5JOcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MO = []\n",
        "\n",
        "for i, L in enumerate(myo):\n",
        "  #print(L)\n",
        "  MOo = []\n",
        "  for j in range(np.size(L, 0)):\n",
        "    Lo = L[j:j+1]\n",
        "    Lo = Lo.values.tolist()\n",
        "    Lo = Lo[0]\n",
        "    opL = op[i].values.tolist()\n",
        "    P = opL[j:j+1]\n",
        "    P = P[0]\n",
        "    for t in k:\n",
        "      Lo.append(t)\n",
        "    MOo.append(Lo)\n",
        "  MO.append(MOo)\n",
        "print(np.size(MO, 0))\n",
        "print(np.size(MO, 1))\n",
        "print(np.size(MO, 2))"
      ],
      "metadata": {
        "id": "ElvekusoxLSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat myo with opt\n",
        "x_val = MO[0]\n",
        "x_val = np.asarray(x_val)\n",
        "print(np.size(x_val, 0))\n",
        "print(np.size(x_val, 1))\n",
        "y_val = labels[0]\n",
        "y_val = np.asarray(y_val)\n",
        "print(np.size(y_val, 0))\n",
        "print(np.size(y_val, 1))\n",
        "\n",
        "sequence_length = 40\n",
        "step = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "for batch in dataset_val.take(1):\n",
        "    inputs, targets = batch\n",
        "print(inputs.shape[0])\n",
        "print(inputs.shape[1])\n",
        "\n",
        "DS_T = [];\n",
        "for i, M in enumerate(MO[1:]):\n",
        "  if np.size(M, 0)<sequence_length:\n",
        "    continue\n",
        "  i = i+1\n",
        "  x_train = M\n",
        "  ishape = []\n",
        "  ishape.append(1)\n",
        "  ishape.append(np.size(M, 1))\n",
        "  y_train = labels[i]\n",
        "  oshape = []\n",
        "  oshape.append(1)\n",
        "  oshape.append(np.size(labels[i], 1))\n",
        "  dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "  DS_T.append(dataset_train)\n",
        "\n",
        "path_checkpoint3 =  \"model3_checkpoint.h5\"\n",
        "path_checkpoint4 =  \"model4_checkpoint.h5\"\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "modelckpt_callback3 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint3,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback4 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint4,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "\n",
        "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "lstm_out = keras.layers.LSTM(32)(inputs)\n",
        "LSoutputs = keras.layers.Dense(oshape[1])(lstm_out)\n",
        "\n",
        "\n",
        "model4 = keras.Model(inputs=inputs, outputs=LSoutputs)\n",
        "model4.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model4.summary()\n",
        "\n",
        "for dataset_train in DS_T:\n",
        "  print(dataset_train)\n",
        "  history4 = model4.fit(\n",
        "      dataset_train,\n",
        "      epochs=epochs,\n",
        "      validation_data=dataset_val,\n",
        "      callbacks=[es_callback, modelckpt_callback4],\n",
        "  )\n",
        "  model2.reset_states() \n",
        "\n",
        "len = np.size(MO[0], 0)\n",
        "h = 10\n",
        "TrainDx = []\n",
        "TrainDy = []\n",
        "TestDx = []\n",
        "TestDy = []\n",
        "for j in range(len-h):\n",
        "  #TD.append(myo[i:(h+1), 1:3])\n",
        "  TestDx.append(MO[0][j:j+h])\n",
        "  TestDy.append(labels[0][j+h-1:j+h])\n",
        "\n",
        "for k, L in  enumerate(MO[1:]):\n",
        "  if np.size(L, 0)<h:\n",
        "    continue\n",
        "  for j in range(len-h):\n",
        "    #TD.append(myo[i:(h+1), 1:3])\n",
        "    TrainDx.append(L[j:j+h])\n",
        "    TrainDy.append(labels[k+1][j+h-1:j+h])\n",
        "\n",
        "TrainDx = np.asarray(TrainDx)\n",
        "TrainDx = TrainDx.reshape(np.size(TrainDx, 0), np.size(TrainDx, 1), np.size(TrainDx, 2), 1)\n",
        "\n",
        "TrainDy = np.asarray(TrainDy)\n",
        "\n",
        "TestDx = np.asarray(TestDx)\n",
        "TestDx = TestDx.reshape(np.size(TestDx, 0), np.size(TestDx, 1), np.size(TestDx, 2), 1)\n",
        "\n",
        "TestDy = np.asarray(TestDy)\n",
        "\n",
        "input_shape = (np.size(TrainDx, 0), np.size(TrainDx, 1), np.size(TrainDx, 2), 1)\n",
        "Kern1 = [2,1,1]\n",
        "Kern2 = [3,3,2]\n",
        "Kern = Kern1\n",
        "\n",
        "inputs = keras.layers.Input(shape=input_shape[1:])\n",
        "cnn_out1 = keras.layers.Conv2D(16, kernel_size = (3, Kern[0]), activation = 'relu', input_shape = input_shape[1:])(inputs)\n",
        "cnn_out2 = keras.layers.Conv2D(32, kernel_size = (3, Kern[1]), activation = 'relu')(cnn_out1)\n",
        "cnn_out3 = keras.layers.MaxPooling2D(pool_size = (2, Kern[2]))(cnn_out2)\n",
        "cnn_out4 = keras.layers.Flatten()(cnn_out3)\n",
        "cnn_out5 = keras.layers.Dense(64, activation = 'relu')(cnn_out4)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1], activation = 'softmax')(cnn_out5)\n",
        "model3 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model3.summary()\n",
        "\n",
        "history3 = model3.fit(\n",
        "  TrainDx, TrainDy,\n",
        "  batch_size = batch_size,\n",
        "  epochs = epochs,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestDx, TestDy),\n",
        "  callbacks=[es_callback, modelckpt_callback3]\n",
        ")"
      ],
      "metadata": {
        "id": "AFlZhsWouX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.sampleEducbaModels import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as sampleEducba\n",
        "import numpy as np\n",
        "#Loading the mnist dataset for the sample purpose\n",
        "(TrainV1, TrainV2), (TestV1, TestV2) = mnist.load_data()\n",
        "#modify the existing data set for our requirement of the sampleEducbaModel.\n",
        "rImg, columnsOfImage = 28, 28\n",
        "if sampleEducba.image_data_format() == 'channels_first':\n",
        "  TrainV1 = TrainV1.reshape(TrainV1.shape[0], 1, rImg, columnsOfImage)\n",
        "  TestV1 = TestV1.reshape(TestV1.shape[0], 1, rImg, columnsOfImage)\n",
        "  input_shape = (1, rImg, columnsOfImage)\n",
        "else:\n",
        "  TrainV1 = TrainV1.reshape(TrainV1.shape[0], rImg, columnsOfImage, 1)\n",
        "  TestV1 = TestV1.reshape(TestV1.shape[0], rImg, columnsOfImage, 1)\n",
        "  input_shape = (rImg, columnsOfImage, 1)\n",
        "TrainV1 = TrainV1.astype('float32')\n",
        "TestV1 = TestV1.astype('float32')\n",
        "TrainV1 /= 255\n",
        "TestV1 /= 255\n",
        "TrainV2 = keras.utils.to_categorical(TrainV2, 10)\n",
        "TestV2 = keras.utils.to_categorical(TestV2, 10)\n",
        "#Model creation\n",
        "Model = Sequential()\n",
        "Model.add(Conv2D(32, kernel_size = (3, 3),\n",
        "activation = 'relu', input_shape = input_shape))\n",
        "Model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "Model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "Model.add(Dropout(0.25)) \n",
        "Model.add(Flatten())\n",
        "Model.add(Dense(128, activation = 'relu'))\n",
        "Model.add(Dropout(0.5))\n",
        "Model.add(Dense(10, activation = 'softmax'))\n",
        "# Model compilation\n",
        "Model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])\n",
        "# training the sampleEducbaModel by using fit function\n",
        "Model.fit(\n",
        "  TrainV1, TrainV2,\n",
        "  batch_size = 128,\n",
        "  epochs = 12,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestV1, TestV2)\n",
        ")"
      ],
      "metadata": {
        "id": "sDLsxTAUF97Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}