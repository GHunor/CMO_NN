{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1q6ZiZBYdgXcuucMVImct1ICE0ZCmC4YC",
      "authorship_tag": "ABX9TyM5KBdBAPXOvzoY9uo19IRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHunor/CMO_NN/blob/main/CMO_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11SGtxoF8-n9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "J0rxH7VHXCaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_path = \"/content/dataset_all.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./DS_o\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_labels.zip\"\n",
        "#zip_path = keras.utils.get_file(origin=uri, fname=\"data_labels0.zip\")\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./labels\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_myo.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./myo\")\n",
        "\n",
        "labels_path = \"/content/DS_o/dataset_opt.zip\"\n",
        "zip_file = ZipFile(labels_path)\n",
        "zip_file.extractall(\"./op\")"
      ],
      "metadata": {
        "id": "grSS5FJ_9CHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myodim = 8\n",
        "labdim = 15\n",
        "optdim = 9"
      ],
      "metadata": {
        "id": "RDdDo_CaUwTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizeL = [];\n",
        "sizeM = [];\n",
        "sizeO = [];"
      ],
      "metadata": {
        "id": "xt6huF11qTDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_ADRS = [];\n",
        "hp = './labels'\n",
        "p = '/'\n",
        "for child in sorted(Path(hp).iterdir()):\n",
        "    if child.is_file():\n",
        "        L_ADRS.append(child.name)\n",
        "labels = [];\n",
        "for adrs in L_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#df = pd.read_csv(hp + p + adrs, header=None)\n",
        "    labels.append(df)\n",
        "    sizeL.append(df.shape)"
      ],
      "metadata": {
        "id": "fqOaESPBSfSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M_ADRS = [];\n",
        "hp = './myo'\n",
        "p = '/'\n",
        "for child in sorted(Path(hp).iterdir()):\n",
        "    if child.is_file():\n",
        "        M_ADRS.append(child.name)\n",
        "myo = [];\n",
        "for adrs in M_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#= pd.read_csv(hp + p + adrs, header=None)\n",
        "    myo.append(df)\n",
        "    sizeM.append(df.shape)"
      ],
      "metadata": {
        "id": "LrWD-KPzZVqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "O_ADRS = [];\n",
        "hp = './op'\n",
        "p = '/'\n",
        "for child in sorted(Path(hp).iterdir()):\n",
        "    if child.is_file():\n",
        "        O_ADRS.append(child.name)\n",
        "op = [];\n",
        "for adrs in O_ADRS:\n",
        "    df = np.genfromtxt(hp + p + adrs, delimiter=\",\")#df = pd.read_csv(hp + p + adrs, header=None)\n",
        "    op.append(df)\n",
        "    sizeO.append(df.shape)"
      ],
      "metadata": {
        "id": "DwdKZutgZVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  df = pd.read_csv('./labels/' + ADRS[0])\n",
        "  labels = [];\n",
        "  labels.append(df)\n",
        "  df = pd.read_csv('./labels/' + ADRS[1])\n",
        "  labels.append(df)\n",
        "  print(labels)\n",
        "  print(labels[1])\n",
        "  print(df)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "d1XCwo_MTXny",
        "outputId": "c9fa9f8d-30e4-4cac-c0af-541e5f5348a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  df = pd.read_csv('./labels/' + ADRS[0])\\n  labels = [];\\n  labels.append(df)\\n  df = pd.read_csv('./labels/' + ADRS[1])\\n  labels.append(df)\\n  print(labels)\\n  print(labels[1])\\n  print(df)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADRS = pd.read_csv(csv_path)\n",
        "#df = pd.read_csv(ADRS(i))\n"
      ],
      "metadata": {
        "id": "v07hnZzKgWu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset and labels\n",
        "\n",
        "#model.reset_states() before feeding the new dataset and calling model.fit()\n",
        "# only myo 15 moves\n",
        "\n",
        "# opto too 15 moves\n",
        "\n",
        "# Have a CNN run thorugh 10 datappoint (one data point represents 10 ns)\n",
        "# 1. only CNN (17->18-20)\n",
        "# 2. only LSTM\n",
        "# 3. Both"
      ],
      "metadata": {
        "id": "sfrOZ9PC9lFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.size(myo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLK4UUdFEzPO",
        "outputId": "8d7c4f5d-0405-4e0b-f85d-e8c6a2dfdf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return asarray(a).size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#opt lstm\n",
        "x_val = op[0]\n",
        "y_val = labels[0]\n",
        "\n",
        "sequence_length = 20\n",
        "step = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "for batch in dataset_val.take(1):\n",
        "    inputs, targets = batch\n",
        "\n",
        "\n",
        "x_test = op[1]\n",
        "y_test = labels[1]\n",
        "\n",
        "DS_T = [];\n",
        "for i, M in enumerate(op[2:]):\n",
        "  if np.size(M, 0)<sequence_length:\n",
        "    continue\n",
        "  i = i+2\n",
        "  print(i)\n",
        "  x_train = M\n",
        "  ishape = []\n",
        "  ishape.append(1)\n",
        "  ishape.append(np.size(M, 1))\n",
        "  y_train = labels[i]\n",
        "  oshape = []\n",
        "  oshape.append(1)\n",
        "  oshape.append(np.size(labels[i], 1))\n",
        "  dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "  DS_T.append(dataset_train)\n",
        "\n",
        "path_checkpoint5 =  \"model5_checkpoint.h5\"\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "\n",
        "\n",
        "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "lstm_out = keras.layers.LSTM(32)(inputs)\n",
        "LSoutputs = keras.layers.Dense(oshape[1])(lstm_out)\n",
        "\n",
        "model5 = keras.Model(inputs=inputs, outputs=LSoutputs)\n",
        "model5.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "model5.summary()\n",
        "\n",
        "modelckpt_callback5 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint5,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# will be repeated\n",
        "for dataset_train in DS_T:\n",
        "  print(dataset_train)\n",
        "  history = model5.fit(\n",
        "      dataset_train,\n",
        "      epochs=epochs,\n",
        "      validation_data=dataset_val,\n",
        "      callbacks=[es_callback, modelckpt_callback5],\n",
        "      verbose = 0\n",
        "  )\n",
        "  model5.reset_states() \n",
        "\n",
        "\n",
        "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_test,\n",
        "      y_test,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "[score1, score2] = model2.evaluate(dataset_test, verbose = 1) \n",
        "\n",
        "print('Test loss:', score1) \n",
        "print('Test error:', score2)\n",
        "\n",
        "#OPT LSTM"
      ],
      "metadata": {
        "id": "FnNCRpDuS0_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = myo[0]\n",
        "y_val = labels[0]\n",
        "\n",
        "sequence_length = 20\n",
        "step = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "for batch in dataset_val.take(1):\n",
        "    inputs, targets = batch"
      ],
      "metadata": {
        "id": "QVIaJR-iWASW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "i = 1;\n",
        "len = np.size(labels[i], 0)\n",
        "print(len)\n",
        "print(labels[0])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rXlrqkeJn6wC",
        "outputId": "7b2f199c-15ec-4ec7-e48f-5d29289149c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni = 1;\\nlen = np.size(labels[i], 0)\\nprint(len)\\nprint(labels[0])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = myo[1]\n",
        "y_test = labels[1]"
      ],
      "metadata": {
        "id": "ocYnpAFqKMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# will be repeated\n",
        "DS_T = [];\n",
        "for i, M in enumerate(myo[2:]):\n",
        "  if np.size(M, 0)<sequence_length:\n",
        "    continue\n",
        "  i = i+2\n",
        "  print(i)\n",
        "  x_train = M\n",
        "  ishape = []\n",
        "  ishape.append(1)\n",
        "  ishape.append(np.size(M, 1))\n",
        "  y_train = labels[i]\n",
        "  oshape = []\n",
        "  oshape.append(1)\n",
        "  oshape.append(np.size(labels[i], 1))\n",
        "  dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "  DS_T.append(dataset_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "o35Fo2XwnnUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f753952d-95a4-4aa6-e28b-b2887310224c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# will be repeated\n",
        "\n"
      ],
      "metadata": {
        "id": "jf7XuZyqVgDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path_checkpoint1 =  \"model1_checkpoint.h5\"\n",
        "path_checkpoint2 =  \"model2_checkpoint.h5\"\n",
        "path_checkpoint3 =  \"model3_checkpoint.h5\"\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "modelckpt_callback1 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint1,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback2 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint2,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback3 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint3,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")"
      ],
      "metadata": {
        "id": "a41N44C2k33i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLe5uAR18RVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#models\n",
        "#input_shape = (batch_size, sequence_length, ishape[1])\n",
        "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "#inputs = keras.layers.Input(shape=(ishape[0], ishape[1]))\n",
        "#inputs = keras.layers.Input(shape=(1,17))\n",
        "\n",
        "\n",
        "lstm_out = keras.layers.LSTM(32)(inputs)\n",
        "LSoutputs = keras.layers.Dense(oshape[1])(lstm_out)\n",
        "\n",
        "\"\"\"\n",
        "cnn_out1 = keras.layers.Conv1D(32, 1, activation='relu',input_shape=(inputs.shape[1], inputs.shape[2]))(inputs)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1])(cnn_out1)\n",
        "model1 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model1.summary()\n",
        "\"\"\"\n",
        "\n",
        "#x = tf.ones((batch_size, inputs.shape[1], inputs.shape[1]))\n",
        "#y = model1(x)\n",
        "#model1.summary()\n",
        "\n",
        "model2 = keras.Model(inputs=inputs, outputs=LSoutputs)\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "model2.summary()\n",
        "\n",
        "\"\"\"\n",
        "lstm_out2 = keras.layers.LSTM(32)(cnn_out1)\n",
        "COMBoutputs = keras.layers.Dense(oshape[1])(lstm_out2)\n",
        "model3 = keras.Model(inputs=inputs, outputs=COMBoutputs)\n",
        "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "model3.summary()\n",
        "\"\"\"\n",
        "\n",
        "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint1,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# will be repeated\n",
        "for dataset_train in DS_T:\n",
        "  print(dataset_train)\n",
        "  history2 = model2.fit(\n",
        "      dataset_train,\n",
        "      epochs=epochs,\n",
        "      validation_data=dataset_val,\n",
        "      callbacks=[es_callback, modelckpt_callback2],\n",
        "      verbose = 0\n",
        "  )\n",
        "  model2.reset_states() \n",
        "\n",
        "  #x_test = x_val,\n",
        "#y_test = y_val,\n",
        "\n",
        "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_test,\n",
        "      y_test,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "[score1, score2] = model2.evaluate(dataset_test, verbose = 1) \n",
        "\n",
        "#print(score)\n",
        "#print(np.size(score))\n",
        "print('Test loss:', score1) \n",
        "print('Test error:', score2)"
      ],
      "metadata": {
        "id": "pFtmZprc-Fc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c7899f-de48-4383-c227-a723a7bd57b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20, 8)]           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                5248      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                495       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,743\n",
            "Trainable params: 5,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04120\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04120\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0699 - root_mean_squared_error: 0.2644\n",
            "Test loss: 0.06992442905902863\n",
            "Test error: 0.26443228125572205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqGdveimZ5e-",
        "outputId": "98d473ff-5a90-47c7-f038-9e6aa95195d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0636 - root_mean_squared_error: 0.2522\n",
            "Test loss: 0.06361017376184464\n",
            "Test error: 0.2522105574607849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sizeL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydh-a9gLrnKq",
        "outputId": "4995f8c8-1fef-4ac9-a010-58c9306172da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(118, 15), (39, 15), (39, 15), (38, 15), (38, 15), (39, 15), (39, 15), (38, 15), (38, 15), (38, 15), (38, 15), (38, 15), (39, 15), (38, 15), (38, 15), (38, 15), (38, 15), (38, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (38, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (38, 15), (39, 15), (39, 15), (38, 15), (38, 15), (38, 15), (37, 15), (37, 15), (38, 15), (38, 15), (12, 15), (38, 15), (39, 15), (39, 15), (38, 15), (39, 15), (38, 15), (39, 15), (39, 15), (39, 15), (40, 15), (39, 15), (40, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (39, 15), (37, 15), (39, 15), (39, 15), (39, 15)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sizeM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djyWXnCyrsDq",
        "outputId": "b7924a6b-30d8-44cc-bd57-0207eb60ca0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(118, 8), (39, 8), (39, 8), (38, 8), (38, 8), (39, 8), (39, 8), (38, 8), (38, 8), (38, 8), (38, 8), (38, 8), (39, 8), (38, 8), (38, 8), (38, 8), (38, 8), (38, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (38, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (38, 8), (39, 8), (39, 8), (38, 8), (38, 8), (38, 8), (37, 8), (37, 8), (38, 8), (38, 8), (12, 8), (38, 8), (39, 8), (39, 8), (38, 8), (39, 8), (38, 8), (39, 8), (39, 8), (39, 8), (40, 8), (39, 8), (40, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (39, 8), (37, 8), (39, 8), (39, 8), (39, 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sizeO)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlhHAvX8rtVy",
        "outputId": "5ee974ac-5ebc-465c-e218-9e5d60dcd8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(118, 9), (39, 9), (39, 9), (38, 9), (38, 9), (39, 9), (39, 9), (38, 9), (38, 9), (38, 9), (38, 9), (38, 9), (39, 9), (38, 9), (38, 9), (38, 9), (38, 9), (38, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (38, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (38, 9), (39, 9), (39, 9), (38, 9), (38, 9), (38, 9), (37, 9), (37, 9), (38, 9), (38, 9), (12, 9), (38, 9), (39, 9), (39, 9), (38, 9), (39, 9), (38, 9), (39, 9), (39, 9), (39, 9), (40, 9), (39, 9), (40, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (39, 9), (37, 9), (39, 9), (39, 9), (39, 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess time series into \"pics\"\n",
        "len = np.size(myo[0], 0)\n",
        "h = 8\n",
        "TrainDx = np.empty([0, h, myodim, 1]).astype('float32')\n",
        "TrainDy = np.empty([0, labdim, 1]).astype('float32')\n",
        "TestDx = np.empty([0, h, myodim, 1]).astype('float32')\n",
        "TestDy = np.empty([0, labdim, 1]).astype('float32')\n",
        "for j in range(len-h):\n",
        "  #TD.append(myo[i:(h+1), 1:3])\n",
        "  arr =  myo[0][j:j+h]\n",
        "  arr = np.reshape(arr, [1,  h, myodim, 1])\n",
        "  TestDx = np.append(TestDx, arr, axis=0)\n",
        "\n",
        "  arr =  labels[0][j+h-1:j+h]\n",
        "  arr = np.reshape(arr, [1,  labdim, 1])\n",
        "  TestDy = np.append(TestDy, arr, axis=0)\n",
        "\n",
        "for k, L in  enumerate(myo[1:]):\n",
        "  if np.size(L, 0)<h:\n",
        "    continue\n",
        "  len2 = np.size(L, 0)\n",
        "  for j in range(len2-h):\n",
        "    #TD.append(myo[i:(h+1), 1:3])\n",
        "    arr =  np.asarray(L[j:j+h])\n",
        "    arr = np.reshape(arr, [1,  h, myodim, 1])\n",
        "\n",
        "    TrainDx = np.append(TrainDx, arr, axis=0)\n",
        "\n",
        "    arr =  labels[k+1][j+h-1:j+h]\n",
        "\n",
        "    arr = np.reshape(arr, [1,  labdim, 1])\n",
        "    TrainDy = np.append(TrainDy, arr, axis=0)\n",
        "\n",
        "#print(TrainDx[0])\n",
        "print(\"TrainDx size:\")\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "print(np.size(TrainDx[0], 0))\n",
        "#print(np.size(TrainDx, 2))\n",
        "#print(TrainDy[0])\n",
        "print(np.size(TrainDy, 0))\n",
        "#print(np.size(TrainDy, 1))\n",
        "#print(labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLxsFlVCLeHp",
        "outputId": "da318139-3aab-4f27-dd9e-d941e99f61fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainDx size:\n",
            "123584\n",
            "1931\n",
            "8\n",
            "1931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "TrainDx = np.asarray(TrainDx)\n",
        "print(np.size(TrainDx))\n",
        "print(np.size(TrainDx, 0))\n",
        "arr = np.array(TrainDx)\n",
        "print(np.size(arr))\n",
        "print(np.size(arr, 0))\n",
        "TrainDx = TrainDx.reshape(np.size(TrainDx, 0), h, 8, 1)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3GWb8t2IfU3K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6f550bf8-6f4b-4955-88d7-74dee4a51fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(np.size(TrainDx))\\nprint(np.size(TrainDx, 0))\\nTrainDx = np.asarray(TrainDx)\\nprint(np.size(TrainDx))\\nprint(np.size(TrainDx, 0))\\narr = np.array(TrainDx)\\nprint(np.size(arr))\\nprint(np.size(arr, 0))\\nTrainDx = TrainDx.reshape(np.size(TrainDx, 0), h, 8, 1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(TrainDx.dtypes)\n",
        "#print(TrainDy.dtypes)"
      ],
      "metadata": {
        "id": "JAdlh7ZuMQ3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TrainDy = np.asarray(TrainDy).astype('float32')"
      ],
      "metadata": {
        "id": "BpZh9djvhQU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestDx = np.asarray(TestDx).astype('float32')\n",
        "TestDx = TestDx.reshape(np.size(TestDx, 0), np.size(TestDx, 1), np.size(TestDx, 2), 1)\n",
        "\n",
        "TestDy = np.asarray(TestDy).astype('float32')"
      ],
      "metadata": {
        "id": "eTRpx8e2hAsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = TrainDx.shape\n",
        "print(input_shape)\n",
        "Kern1 = [2,1,1]\n",
        "Kern2 = [3,3,2]\n",
        "Kern = Kern2"
      ],
      "metadata": {
        "id": "JR1HoTu-iScj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c766b29e-1167-4899-8b77-0b0ef17b9e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1931, 8, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(input_shape)\n",
        "inputs = keras.layers.Input(shape=input_shape[1:])\n",
        "cnn_out1 = keras.layers.Conv2D(16, kernel_size = (3, Kern[0]), activation = 'relu', input_shape = input_shape[1:])(inputs)\n",
        "cnn_out2 = keras.layers.Conv2D(32, kernel_size = (3, Kern[1]), activation = 'relu')(cnn_out1)\n",
        "cnn_out3 = keras.layers.MaxPooling2D(pool_size = (2, Kern[2]))(cnn_out2)\n",
        "cnn_out4 = keras.layers.Flatten()(cnn_out3)\n",
        "cnn_out5 = keras.layers.Dense(64, activation = 'relu')(cnn_out4)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1], activation = 'softmax')(cnn_out5)\n",
        "model1 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "model1.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzoQ84d5JOcB",
        "outputId": "6a2f33da-8643-476c-9c33-bb77f77c77e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1931, 8, 8, 1)\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 6, 6, 16)          160       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 4, 4, 32)          4640      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 2, 2, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 15)                975       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,031\n",
            "Trainable params: 14,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 11):\n",
        "  history1 = model1.fit(\n",
        "  TrainDx, TrainDy,\n",
        "  batch_size = batch_size,\n",
        "  epochs = 20,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestDx, TestDy),\n",
        "  callbacks=[es_callback, modelckpt_callback1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6KcKnGM2bl1",
        "outputId": "bf9b80ee-47e4-41c6-9797-ef59f4d01b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4233 - root_mean_squared_error: 0.6506\n",
            "Epoch 1: val_loss improved from inf to 0.46542, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 5s 12ms/step - loss: 0.4233 - root_mean_squared_error: 0.6506 - val_loss: 0.4654 - val_root_mean_squared_error: 0.6822\n",
            "Epoch 2/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4136 - root_mean_squared_error: 0.6431\n",
            "Epoch 2: val_loss improved from 0.46542 to 0.46260, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4137 - root_mean_squared_error: 0.6432 - val_loss: 0.4626 - val_root_mean_squared_error: 0.6801\n",
            "Epoch 3/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4107 - root_mean_squared_error: 0.6409\n",
            "Epoch 3: val_loss improved from 0.46260 to 0.46213, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4127 - root_mean_squared_error: 0.6424 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 4/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4130 - root_mean_squared_error: 0.6427\n",
            "Epoch 4: val_loss did not improve from 0.46213\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 5/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4099 - root_mean_squared_error: 0.6403\n",
            "Epoch 5: val_loss did not improve from 0.46213\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 6/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4109 - root_mean_squared_error: 0.6410\n",
            "Epoch 6: val_loss improved from 0.46213 to 0.46199, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6424\n",
            "Epoch 7: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 8/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4101 - root_mean_squared_error: 0.6404\n",
            "Epoch 8: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4623 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 9/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4106 - root_mean_squared_error: 0.6408\n",
            "Epoch 9: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 10/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4134 - root_mean_squared_error: 0.6430\n",
            "Epoch 10: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 11/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 11: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 1/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6424\n",
            "Epoch 1: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 2/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4128 - root_mean_squared_error: 0.6425\n",
            "Epoch 2: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 3/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6417\n",
            "Epoch 3: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 4/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 4: val_loss improved from 0.46199 to 0.46199, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 5/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4180 - root_mean_squared_error: 0.6465\n",
            "Epoch 5: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 6/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4163 - root_mean_squared_error: 0.6452\n",
            "Epoch 6: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 7/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4128 - root_mean_squared_error: 0.6425\n",
            "Epoch 7: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4624 - val_root_mean_squared_error: 0.6800\n",
            "Epoch 8/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4129 - root_mean_squared_error: 0.6426\n",
            "Epoch 8: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 9/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4129 - root_mean_squared_error: 0.6426\n",
            "Epoch 9: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6423\n",
            "Epoch 1: val_loss did not improve from 0.46199\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 2/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4137 - root_mean_squared_error: 0.6432\n",
            "Epoch 2: val_loss improved from 0.46199 to 0.46198, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 3/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4100 - root_mean_squared_error: 0.6403\n",
            "Epoch 3: val_loss did not improve from 0.46198\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4623 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6423\n",
            "Epoch 4: val_loss did not improve from 0.46198\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 5/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4132 - root_mean_squared_error: 0.6428\n",
            "Epoch 5: val_loss did not improve from 0.46198\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 6/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4121 - root_mean_squared_error: 0.6420\n",
            "Epoch 6: val_loss improved from 0.46198 to 0.46194, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 7/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4125 - root_mean_squared_error: 0.6422\n",
            "Epoch 7: val_loss did not improve from 0.46194\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 0.4623 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 8/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6423\n",
            "Epoch 8: val_loss did not improve from 0.46194\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4126 - root_mean_squared_error: 0.6423 - val_loss: 0.4623 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 9/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4133 - root_mean_squared_error: 0.6429\n",
            "Epoch 9: val_loss did not improve from 0.46194\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6798\n",
            "Epoch 10/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4135 - root_mean_squared_error: 0.6431\n",
            "Epoch 10: val_loss did not improve from 0.46194\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 11/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4103 - root_mean_squared_error: 0.6405\n",
            "Epoch 11: val_loss improved from 0.46194 to 0.46193, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 12/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6415\n",
            "Epoch 12: val_loss improved from 0.46193 to 0.46183, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6422 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4125 - root_mean_squared_error: 0.6422\n",
            "Epoch 13: val_loss did not improve from 0.46183\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6422 - val_loss: 0.4621 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 14/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4124 - root_mean_squared_error: 0.6422\n",
            "Epoch 14: val_loss did not improve from 0.46183\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4125 - root_mean_squared_error: 0.6422 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4125 - root_mean_squared_error: 0.6422\n",
            "Epoch 15: val_loss improved from 0.46183 to 0.46176, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4125 - root_mean_squared_error: 0.6422 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6795\n",
            "Epoch 16/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6418\n",
            "Epoch 16: val_loss did not improve from 0.46176\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4124 - root_mean_squared_error: 0.6422 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6797\n",
            "Epoch 17/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4100 - root_mean_squared_error: 0.6403\n",
            "Epoch 17: val_loss did not improve from 0.46176\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4124 - root_mean_squared_error: 0.6422 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 18/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4152 - root_mean_squared_error: 0.6444\n",
            "Epoch 18: val_loss did not improve from 0.46176\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4124 - root_mean_squared_error: 0.6422 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 19/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4114 - root_mean_squared_error: 0.6414\n",
            "Epoch 19: val_loss did not improve from 0.46176\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4124 - root_mean_squared_error: 0.6421 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 20/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4122 - root_mean_squared_error: 0.6421\n",
            "Epoch 20: val_loss did not improve from 0.46176\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4123 - root_mean_squared_error: 0.6421 - val_loss: 0.4619 - val_root_mean_squared_error: 0.6796\n",
            "Epoch 1/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4125 - root_mean_squared_error: 0.6423\n",
            "Epoch 1: val_loss improved from 0.46176 to 0.46171, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.4123 - root_mean_squared_error: 0.6421 - val_loss: 0.4617 - val_root_mean_squared_error: 0.6795\n",
            "Epoch 2/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4146 - root_mean_squared_error: 0.6439\n",
            "Epoch 2: val_loss did not improve from 0.46171\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4123 - root_mean_squared_error: 0.6421 - val_loss: 0.4618 - val_root_mean_squared_error: 0.6795\n",
            "Epoch 3/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4106 - root_mean_squared_error: 0.6407\n",
            "Epoch 3: val_loss improved from 0.46171 to 0.46164, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4123 - root_mean_squared_error: 0.6421 - val_loss: 0.4616 - val_root_mean_squared_error: 0.6794\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 4: val_loss improved from 0.46164 to 0.46162, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4123 - root_mean_squared_error: 0.6421 - val_loss: 0.4616 - val_root_mean_squared_error: 0.6794\n",
            "Epoch 5/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 5: val_loss improved from 0.46162 to 0.46144, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4122 - root_mean_squared_error: 0.6421 - val_loss: 0.4614 - val_root_mean_squared_error: 0.6793\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4122 - root_mean_squared_error: 0.6420\n",
            "Epoch 6: val_loss did not improve from 0.46144\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4122 - root_mean_squared_error: 0.6420 - val_loss: 0.4615 - val_root_mean_squared_error: 0.6793\n",
            "Epoch 7/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4137 - root_mean_squared_error: 0.6432\n",
            "Epoch 7: val_loss improved from 0.46144 to 0.46138, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4122 - root_mean_squared_error: 0.6420 - val_loss: 0.4614 - val_root_mean_squared_error: 0.6793\n",
            "Epoch 8/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4149 - root_mean_squared_error: 0.6441\n",
            "Epoch 8: val_loss improved from 0.46138 to 0.46126, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4122 - root_mean_squared_error: 0.6420 - val_loss: 0.4613 - val_root_mean_squared_error: 0.6792\n",
            "Epoch 9/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4143 - root_mean_squared_error: 0.6436\n",
            "Epoch 9: val_loss did not improve from 0.46126\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4122 - root_mean_squared_error: 0.6420 - val_loss: 0.4613 - val_root_mean_squared_error: 0.6792\n",
            "Epoch 10/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4132 - root_mean_squared_error: 0.6428\n",
            "Epoch 10: val_loss improved from 0.46126 to 0.46125, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4121 - root_mean_squared_error: 0.6420 - val_loss: 0.4612 - val_root_mean_squared_error: 0.6792\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4121 - root_mean_squared_error: 0.6420\n",
            "Epoch 11: val_loss did not improve from 0.46125\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4121 - root_mean_squared_error: 0.6420 - val_loss: 0.4612 - val_root_mean_squared_error: 0.6792\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4121 - root_mean_squared_error: 0.6420\n",
            "Epoch 12: val_loss improved from 0.46125 to 0.46115, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4121 - root_mean_squared_error: 0.6420 - val_loss: 0.4612 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 13/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 13: val_loss improved from 0.46115 to 0.46110, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4121 - root_mean_squared_error: 0.6419 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 14/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4129 - root_mean_squared_error: 0.6426\n",
            "Epoch 14: val_loss did not improve from 0.46110\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4121 - root_mean_squared_error: 0.6419 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 15/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4089 - root_mean_squared_error: 0.6395\n",
            "Epoch 15: val_loss improved from 0.46110 to 0.46102, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4121 - root_mean_squared_error: 0.6419 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 16/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4122 - root_mean_squared_error: 0.6420\n",
            "Epoch 16: val_loss did not improve from 0.46102\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 17: val_loss did not improve from 0.46102\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 18: val_loss did not improve from 0.46102\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 19/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 19: val_loss did not improve from 0.46102\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 20: val_loss did not improve from 0.46102\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 1: val_loss improved from 0.46102 to 0.46087, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 2/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4122 - root_mean_squared_error: 0.6420\n",
            "Epoch 2: val_loss did not improve from 0.46087\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4120 - root_mean_squared_error: 0.6419 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 3/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6424\n",
            "Epoch 3: val_loss improved from 0.46087 to 0.46081, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4120 - root_mean_squared_error: 0.6418 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 4/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 4: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4120 - root_mean_squared_error: 0.6418 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6418\n",
            "Epoch 5: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4120 - root_mean_squared_error: 0.6418 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 6/20\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.4120 - root_mean_squared_error: 0.6419\n",
            "Epoch 6: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4612 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 7/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4102 - root_mean_squared_error: 0.6405\n",
            "Epoch 7: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 8: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 1/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4130 - root_mean_squared_error: 0.6427\n",
            "Epoch 1: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 2/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4088 - root_mean_squared_error: 0.6394\n",
            "Epoch 2: val_loss did not improve from 0.46081\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 3/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4149 - root_mean_squared_error: 0.6441\n",
            "Epoch 3: val_loss improved from 0.46081 to 0.46074, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 4/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4087 - root_mean_squared_error: 0.6393\n",
            "Epoch 4: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 5/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 5: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 6/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 6: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 7/20\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4139 - root_mean_squared_error: 0.6433\n",
            "Epoch 7: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 8/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4124 - root_mean_squared_error: 0.6422\n",
            "Epoch 8: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 1/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4105 - root_mean_squared_error: 0.6407\n",
            "Epoch 1: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 2/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 2: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4119 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 3/20\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6416\n",
            "Epoch 3: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4118 - root_mean_squared_error: 0.6418 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 4/20\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 4: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6417\n",
            "Epoch 5: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 6/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 6: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 7/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4098 - root_mean_squared_error: 0.6402\n",
            "Epoch 7: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 8/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4104 - root_mean_squared_error: 0.6406\n",
            "Epoch 8: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 9/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6418\n",
            "Epoch 9: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 10/20\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.4130 - root_mean_squared_error: 0.6426\n",
            "Epoch 10: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 11/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4134 - root_mean_squared_error: 0.6430\n",
            "Epoch 11: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 12/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 12: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 13/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4127 - root_mean_squared_error: 0.6424\n",
            "Epoch 13: val_loss did not improve from 0.46074\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 14/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4110 - root_mean_squared_error: 0.6411\n",
            "Epoch 14: val_loss improved from 0.46074 to 0.46068, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4118 - root_mean_squared_error: 0.6417 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6787\n",
            "Epoch 15/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4131 - root_mean_squared_error: 0.6427\n",
            "Epoch 15: val_loss did not improve from 0.46068\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 16/20\n",
            "18/31 [================>.............] - ETA: 0s - loss: 0.4150 - root_mean_squared_error: 0.6442\n",
            "Epoch 16: val_loss did not improve from 0.46068\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 17/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 17: val_loss did not improve from 0.46068\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 18/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4108 - root_mean_squared_error: 0.6409\n",
            "Epoch 18: val_loss improved from 0.46068 to 0.46066, saving model to model1_checkpoint.h5\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6787\n",
            "Epoch 19/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4152 - root_mean_squared_error: 0.6444\n",
            "Epoch 19: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 20/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4114 - root_mean_squared_error: 0.6414\n",
            "Epoch 20: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6787\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6417\n",
            "Epoch 1: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4117 - root_mean_squared_error: 0.6417 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 2/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 2: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 3: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 4/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6414\n",
            "Epoch 4: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 5/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 5: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 6/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 6: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 7/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4122 - root_mean_squared_error: 0.6420\n",
            "Epoch 7: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 8/20\n",
            "17/31 [===============>..............] - ETA: 0s - loss: 0.4103 - root_mean_squared_error: 0.6405\n",
            "Epoch 8: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 9/20\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.4095 - root_mean_squared_error: 0.6399\n",
            "Epoch 9: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4117 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 1/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6416\n",
            "Epoch 1: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 2/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6418\n",
            "Epoch 2: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 3/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4114 - root_mean_squared_error: 0.6414\n",
            "Epoch 3: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6787\n",
            "Epoch 4/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 4: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 5/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4109 - root_mean_squared_error: 0.6411\n",
            "Epoch 5: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 6/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6417\n",
            "Epoch 6: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 7/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 7: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 8/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4109 - root_mean_squared_error: 0.6410\n",
            "Epoch 8: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 1/20\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 1: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6415\n",
            "Epoch 2: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 3/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4114 - root_mean_squared_error: 0.6414\n",
            "Epoch 3: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 4/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4123 - root_mean_squared_error: 0.6421\n",
            "Epoch 4: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 5/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6423\n",
            "Epoch 5: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 6/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6415\n",
            "Epoch 6: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6791\n",
            "Epoch 7/20\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4111 - root_mean_squared_error: 0.6412\n",
            "Epoch 7: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 8/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6417\n",
            "Epoch 8: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6415\n",
            "Epoch 9: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4116 - root_mean_squared_error: 0.6415 - val_loss: 0.4609 - val_root_mean_squared_error: 0.6789\n",
            "Epoch 10/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4116 - root_mean_squared_error: 0.6416\n",
            "Epoch 10: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 11/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4117 - root_mean_squared_error: 0.6416\n",
            "Epoch 11: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4607 - val_root_mean_squared_error: 0.6787\n",
            "Epoch 12/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 12: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 13/20\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4115 - root_mean_squared_error: 0.6415\n",
            "Epoch 13: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 14/20\n",
            "27/31 [=========================>....] - ETA: 0s - loss: 0.4119 - root_mean_squared_error: 0.6418\n",
            "Epoch 14: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4611 - val_root_mean_squared_error: 0.6790\n",
            "Epoch 15/20\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4114 - root_mean_squared_error: 0.6414\n",
            "Epoch 15: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4608 - val_root_mean_squared_error: 0.6788\n",
            "Epoch 16/20\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.4107 - root_mean_squared_error: 0.6409\n",
            "Epoch 16: val_loss did not improve from 0.46066\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.4115 - root_mean_squared_error: 0.6415 - val_loss: 0.4610 - val_root_mean_squared_error: 0.6790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[score1, score2] = model1.evaluate(TestDx, TestDy, verbose = 1) \n",
        "\n",
        "print('Test loss:', score1) \n",
        "print('Test error:', score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nXkRbmJO_97",
        "outputId": "79413014-e028-4a99-a956-576452dc5257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4610 - root_mean_squared_error: 0.6790\n",
            "Test loss: 0.4610118269920349\n",
            "Test error: 0.6789785027503967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MO = []\n",
        "\n",
        "for i, L in enumerate(myo):\n",
        "  T = np.concatenate((myo[i], op[i]), axis=1,  dtype='float32', casting=\"same_kind\")\n",
        "  print(T.shape)\n",
        "  MO.append(T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T1p_npDvLSJ",
        "outputId": "5750d500-676f-4cf8-8f7a-11c165c147d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(37, 17)\n",
            "(37, 17)\n",
            "(38, 17)\n",
            "(38, 17)\n",
            "(12, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(38, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(40, 17)\n",
            "(39, 17)\n",
            "(40, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(37, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n",
            "(39, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concat myo with opt\n",
        "x_val = MO[0]\n",
        "x_val = np.asarray(x_val)\n",
        "#print(np.size(x_val, 0))\n",
        "#print(np.size(x_val, 1))\n",
        "y_val = labels[0]\n",
        "y_val = np.asarray(y_val)\n",
        "#print(np.size(y_val, 0))\n",
        "#print(np.size(y_val, 1))\n",
        "\n",
        "sequence_length = 20\n",
        "step = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "for batch in dataset_val.take(1):\n",
        "    inputs, targets = batch\n",
        "#print(inputs.shape[0])\n",
        "#print(inputs.shape[1])\n",
        "\n",
        "x_test = MO[1]\n",
        "y_test = labels[1]\n",
        "\n",
        "\n",
        "DS_T = [];\n",
        "for i, M in enumerate(MO[2:]):\n",
        "  if np.size(M, 0)<sequence_length:\n",
        "    continue\n",
        "  i = i+2\n",
        "  #print(i)\n",
        "  x_train = M\n",
        "  ishape = []\n",
        "  ishape.append(1)\n",
        "  ishape.append(np.size(M, 1))\n",
        "  y_train = labels[i]\n",
        "  oshape = []\n",
        "  oshape.append(1)\n",
        "  oshape.append(np.size(labels[i], 1))\n",
        "  dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "  DS_T.append(dataset_train)\n",
        "\n",
        "path_checkpoint3 =  \"model3_checkpoint.h5\"\n",
        "path_checkpoint4 =  \"model4_checkpoint.h5\"\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "modelckpt_callback3 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint3,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "modelckpt_callback4 = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=path_checkpoint4,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "AFlZhsWouX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "lstm_out = keras.layers.LSTM(32)(inputs)\n",
        "LSoutputs = keras.layers.Dense(oshape[1])(lstm_out)\n",
        "\n",
        "\n",
        "model4 = keras.Model(inputs=inputs, outputs=LSoutputs)\n",
        "model4.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "model4.summary()\n",
        "\n",
        "for dataset_train in DS_T:\n",
        "  print(dataset_train)\n",
        "  history4 = model4.fit(\n",
        "      dataset_train,\n",
        "      epochs=epochs,\n",
        "      validation_data=dataset_val,\n",
        "      callbacks=[es_callback, modelckpt_callback4],\n",
        "      verbose=0\n",
        "  )\n",
        "  model4.reset_states() \n",
        "\n",
        "\n",
        "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
        "      x_test,\n",
        "      y_test,\n",
        "      sequence_length=sequence_length,\n",
        "      sampling_rate=step,\n",
        "      batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "[score1, score2] = model4.evaluate(dataset_test, verbose = 1) \n",
        "\n",
        "print('Test loss:', score1) \n",
        "print('Test error:', score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKl_CSr53L_r",
        "outputId": "35ea25af-429c-438d-dda2-85e3113a4184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 20, 17)]          0         \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 32)                6400      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 15)                495       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,895\n",
            "Trainable params: 6,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 17), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float64, name=None))>\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.04006\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.04006\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0658 - root_mean_squared_error: 0.2565\n",
            "Test loss: 0.06577369570732117\n",
            "Test error: 0.25646382570266724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MamCl0_IiJyT",
        "outputId": "9365efc3-e3a9-41f5-b7e7-e5124c228d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0634 - root_mean_squared_error: 0.2519\n",
            "Test loss: 0.06343284994363785\n",
            "Test error: 0.25185877084732056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len = np.size(myo[0], 0)\n",
        "h = 8\n",
        "TrainDx = np.empty([0, h, myodim, 1]).astype('float32')\n",
        "TrainDy = np.empty([0, labdim, 1]).astype('float32')\n",
        "TestDx = np.empty([0, h, myodim, 1]).astype('float32')\n",
        "TestDy = np.empty([0, labdim, 1]).astype('float32')\n",
        "for j in range(len-h):\n",
        "  #TD.append(myo[i:(h+1), 1:3])\n",
        "  arr =  myo[0][j:j+h]\n",
        "  arr = np.reshape(arr, [1,  h, myodim, 1])\n",
        "  TestDx = np.append(TestDx, arr, axis=0)\n",
        "\n",
        "  arr =  labels[0][j+h-1:j+h]\n",
        "  arr = np.reshape(arr, [1,  labdim, 1])\n",
        "  TestDy = np.append(TestDy, arr, axis=0)\n",
        "\n",
        "for k, L in  enumerate(myo[1:]):\n",
        "  if np.size(L, 0)<h:\n",
        "    continue\n",
        "  len2 = np.size(L, 0)\n",
        "  for j in range(len2-h):\n",
        "    arr =  np.asarray(L[j:j+h])\n",
        "    arr = np.reshape(arr, [1,  h, myodim, 1])\n",
        "    TrainDx = np.append(TrainDx, arr, axis=0)\n",
        "    arr =  labels[k+1][j+h-1:j+h]\n",
        "    arr = np.reshape(arr, [1,  labdim, 1])\n",
        "    TrainDy = np.append(TrainDy, arr, axis=0)\n",
        "\n",
        "\n",
        "TrainDx = np.asarray(TrainDx)\n",
        "TrainDx = TrainDx.reshape(np.size(TrainDx, 0), np.size(TrainDx, 1), np.size(TrainDx, 2), 1)\n",
        "print(\"TrainDx.shape\")\n",
        "print(TrainDx.shape)\n",
        "\n",
        "TrainDy = np.asarray(TrainDy)\n",
        "\n",
        "TestDx = np.asarray(TestDx)\n",
        "TestDx = TestDx.reshape(np.size(TestDx, 0), np.size(TestDx, 1), np.size(TestDx, 2), 1)\n",
        "\n",
        "TestDy = np.asarray(TestDy)\n",
        "\n",
        "input_shape = (np.size(TrainDx, 0), np.size(TrainDx, 1), np.size(TrainDx, 2), 1)\n",
        "Kern1 = [2,1,1]\n",
        "Kern2 = [3,3,2]\n",
        "Kern = Kern1\n",
        "\n",
        "inputs = keras.layers.Input(shape=input_shape[1:])\n",
        "cnn_out1 = keras.layers.Conv2D(16, kernel_size = (3, Kern[0]), activation = 'relu', input_shape = input_shape[1:])(inputs)\n",
        "cnn_out2 = keras.layers.Conv2D(32, kernel_size = (3, Kern[1]), activation = 'relu')(cnn_out1)\n",
        "cnn_out3 = keras.layers.MaxPooling2D(pool_size = (2, Kern[2]))(cnn_out2)\n",
        "cnn_out4 = keras.layers.Flatten()(cnn_out3)\n",
        "cnn_out5 = keras.layers.Dense(64, activation = 'relu')(cnn_out4)\n",
        "CNNoutputs = keras.layers.Dense(oshape[1], activation = 'softmax')(cnn_out5)\n",
        "model3 = keras.Model(inputs=inputs, outputs=CNNoutputs)\n",
        "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "model3.summary()\n",
        "\n",
        "history3 = model3.fit(\n",
        "  TrainDx, TrainDy,\n",
        "  batch_size = batch_size,\n",
        "  epochs = epochs,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestDx, TestDy),\n",
        "  callbacks=[es_callback, modelckpt_callback3]\n",
        ")\n",
        "\n",
        "[score1, score2] = model3.evaluate(TestDx, TestDy, verbose = 1) \n",
        "\n",
        "print('Test loss:', score1) \n",
        "print('Test error:', score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq9jwrRbV6SL",
        "outputId": "b9289168-027d-42ec-b303-5e80d9bf23f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 6, 7, 16)          112       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 7, 32)          1568      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 7, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 448)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                28736     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 15)                975       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,391\n",
            "Trainable params: 31,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "29/31 [===========================>..] - ETA: 0s - loss: 0.4234 - root_mean_squared_error: 0.6507\n",
            "Epoch 1: val_loss improved from inf to 0.46500, saving model to model3_checkpoint.h5\n",
            "31/31 [==============================] - 1s 12ms/step - loss: 0.4229 - root_mean_squared_error: 0.6503 - val_loss: 0.4650 - val_root_mean_squared_error: 0.6819\n",
            "Epoch 2/5\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4137 - root_mean_squared_error: 0.6432\n",
            "Epoch 2: val_loss improved from 0.46500 to 0.46277, saving model to model3_checkpoint.h5\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4138 - root_mean_squared_error: 0.6433 - val_loss: 0.4628 - val_root_mean_squared_error: 0.6803\n",
            "Epoch 3/5\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.4140 - root_mean_squared_error: 0.6434\n",
            "Epoch 3: val_loss improved from 0.46277 to 0.46223, saving model to model3_checkpoint.h5\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.4131 - root_mean_squared_error: 0.6427 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 4/5\n",
            "25/31 [=======================>......] - ETA: 0s - loss: 0.4118 - root_mean_squared_error: 0.6417\n",
            "Epoch 4: val_loss did not improve from 0.46223\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4127 - root_mean_squared_error: 0.6425 - val_loss: 0.4623 - val_root_mean_squared_error: 0.6799\n",
            "Epoch 5/5\n",
            "30/31 [============================>.] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.6424\n",
            "Epoch 5: val_loss improved from 0.46223 to 0.46201, saving model to model3_checkpoint.h5\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4126 - root_mean_squared_error: 0.6424 - val_loss: 0.4620 - val_root_mean_squared_error: 0.6797\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4620 - root_mean_squared_error: 0.6797\n",
            "Test loss: 0.46200624108314514\n",
            "Test error: 0.6797103881835938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.sampleEducbaModels import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as sampleEducba\n",
        "import numpy as np\n",
        "#Loading the mnist dataset for the sample purpose\n",
        "(TrainV1, TrainV2), (TestV1, TestV2) = mnist.load_data()\n",
        "#modify the existing data set for our requirement of the sampleEducbaModel.\n",
        "rImg, columnsOfImage = 28, 28\n",
        "if sampleEducba.image_data_format() == 'channels_first':\n",
        "  TrainV1 = TrainV1.reshape(TrainV1.shape[0], 1, rImg, columnsOfImage)\n",
        "  TestV1 = TestV1.reshape(TestV1.shape[0], 1, rImg, columnsOfImage)\n",
        "  input_shape = (1, rImg, columnsOfImage)\n",
        "else:\n",
        "  TrainV1 = TrainV1.reshape(TrainV1.shape[0], rImg, columnsOfImage, 1)\n",
        "  TestV1 = TestV1.reshape(TestV1.shape[0], rImg, columnsOfImage, 1)\n",
        "  input_shape = (rImg, columnsOfImage, 1)\n",
        "TrainV1 = TrainV1.astype('float32')\n",
        "TestV1 = TestV1.astype('float32')\n",
        "TrainV1 /= 255\n",
        "TestV1 /= 255\n",
        "TrainV2 = keras.utils.to_categorical(TrainV2, 10)\n",
        "TestV2 = keras.utils.to_categorical(TestV2, 10)\n",
        "#Model creation\n",
        "Model = Sequential()\n",
        "Model.add(Conv2D(32, kernel_size = (3, 3),\n",
        "activation = 'relu', input_shape = input_shape))\n",
        "Model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "Model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "Model.add(Dropout(0.25)) \n",
        "Model.add(Flatten())\n",
        "Model.add(Dense(128, activation = 'relu'))\n",
        "Model.add(Dropout(0.5))\n",
        "Model.add(Dense(10, activation = 'softmax'))\n",
        "# Model compilation\n",
        "Model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])\n",
        "# training the sampleEducbaModel by using fit function\n",
        "Model.fit(\n",
        "  TrainV1, TrainV2,\n",
        "  batch_size = 128,\n",
        "  epochs = 12,\n",
        "  verbose = 1,\n",
        "  validation_data = (TestV1, TestV2)\n",
        ")"
      ],
      "metadata": {
        "id": "sDLsxTAUF97Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}